<!DOCTYPE html>
<html lang="en"><head>
<script src="ols_files/libs/clipboard/clipboard.min.js"></script>
<script src="ols_files/libs/quarto-html/tabby.min.js"></script>
<script src="ols_files/libs/quarto-html/popper.min.js"></script>
<script src="ols_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="ols_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ols_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="ols_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.1.189">

  <meta name="author" content="Justin Smith">
  <title>Ordinary Least Squares</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="ols_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="ols_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="ols_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="ols_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="ols_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="ols_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="ols_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="ols_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="ols_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#43464B" class="center">
  <h1 class="title">Ordinary Least Squares</h1>
  <p class="subtitle">EC655</p>
  <p class="author">Justin Smith</p>
  <p class="institute">Wilfrid Laurier University</p>
  <p class="date">Fall 2022</p>
</section>

<section>
<section id="estimating-parameters-of-the-linear-regression-model" class="title-slide slide level1 center">
<h1>Estimating Parameters of the Linear Regression Model</h1>

</section>
<section id="estimation-by-method-of-moments" class="slide level2">
<h2>Estimation by Method of Moments</h2>
<ul>
<li><p>Recall that the population linear regression model is</p>
<p><span class="math display">\[y = \mathbf{x}\boldsymbol{\beta} + u\]</span></p></li>
<li><p>We wish to estimate the slope parameters of this model</p></li>
<li><p>The first step is to collect a sample <span class="math inline">\(\{(\mathbf{x}_{i},y_{i}): i=1,2,...,n)\}\)</span></p>
<ul>
<li><p>Samples are drawn independently from the same distribution</p></li>
<li><p>This means each is independent and identically distributed (<strong>iid</strong>)</p></li>
</ul></li>
<li><p>The usual method we use for estimation is <strong>Ordinary Least Squares (OLS)</strong></p>
<ul>
<li>Minimize the sum of the squared residuals</li>
</ul></li>
</ul>
</section>
<section id="estimation-by-method-of-moments-1" class="slide level2">
<h2>Estimation by Method of Moments</h2>
<ul>
<li><p>You get the same result with the <strong>Method of Moments</strong></p>
<ul>
<li>Replace the unknown population moments with their sample equivalents</li>
</ul></li>
<li><p>Above we found that the population slopes are</p>
<p><span class="math display">\[\boldsymbol{\beta}=(\textbf{E}[\mathbf{x'x}])^{-1} \textbf{E}[\mathbf{x}'y]\]</span></p></li>
<li><p>Replacing the population expectations with sample means across <span class="math inline">\(n\)</span> observations</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\left ( \frac{1}{n}\sum_{i=1}^{n}\mathbf{x_{i}'x_{i}} \right )^{-1} \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x}_{i}'y_{i}\right ) = \left ( \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}} \right )^{-1} \left ( \sum_{i=1}^{n}\mathbf{x}_{i}'y_{i}\right )\]</span></p></li>
<li><p>Here <span class="math inline">\(i\)</span> indexes the sample observation</p></li>
<li><p><span class="math inline">\(\mathbf{x}_{i}\)</span> is a <span class="math inline">\(1 \times (k+1)\)</span> vector, so <span class="math inline">\(\mathbf{x_{i}'x_{i}}\)</span> is a <span class="math inline">\((k+1) \times (k+1)\)</span> matrix</p></li>
</ul>
</section>
<section id="estimation-by-method-of-moments-2" class="slide level2">
<h2>Estimation by Method of Moments</h2>
<ul>
<li><p>Recall from the matrix review the concept of partitioned matrix multiplication</p>
<ul>
<li>You can break matrices into conformable vectors before multiplication</li>
</ul></li>
<li><p>Based on that concept, we can rewrite</p>
<p><span class="math display">\[\left ( \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}} \right ) = \mathbf{X'X}\]</span> <span class="math display">\[\left ( \sum_{i=1}^{n}\mathbf{x}_{i}'y_{i}\right ) =  \mathbf{X'y}\]</span></p></li>
<li><p>Substituting in, we get an equivalent expression for the estimated slope</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\left (  \mathbf{X'X}\right )^{-1}  \mathbf{X'y}\]</span></p></li>
</ul>
</section>
<section id="ordinary-least-squares" class="slide level2">
<h2>Ordinary Least Squares</h2>
<ul>
<li><p>You get the same the <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> if you use OLS</p>
<p><span class="math display">\[\min_{\boldsymbol{\hat{\beta}}} \sum_{i=1}^{n} (y_{i} - \mathbf{x}_{i}\boldsymbol{\hat{\beta}})^2 = (\mathbf{y} - \mathbf{X}\boldsymbol{\hat{\beta}})'(\mathbf{y} - \mathbf{X}\boldsymbol{\hat{\beta}})\]</span></p></li>
<li><p>Because of this, we will call <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> the <strong>OLS Estimator</strong></p></li>
<li><p>You can use <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> to obtain predicted values of <span class="math inline">\(y\)</span></p>
<p><span class="math display">\[\hat{\mathbf{y}} = \mathbf{X}\boldsymbol{\hat{\beta}}\]</span></p></li>
<li><p>By definition, the residual is the difference between <span class="math inline">\(\mathbf{y}\)</span> and its predicted value</p>
<p><span class="math display">\[\mathbf{y} =  \mathbf{X}\boldsymbol{\hat{\beta}} + \mathbf{\hat{u}}\]</span></p></li>
</ul>
</section>
<section id="ordinary-least-squares-1" class="slide level2">
<h2>Ordinary Least Squares</h2>

<img data-src="sampregress.png" style="width:3.5in" class="r-stretch"></section></section>
<section>
<section id="algebraic-properties-of-ols" class="title-slide slide level1 center">
<h1>Algebraic Properties of OLS</h1>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li><p>OLS is one way to estimate a linear regression model</p></li>
<li><p>It is important to know how well the method works</p></li>
<li><p>One way is to examine the “fit” of our regression line</p>
<ul>
<li><p>How close to the line are the datapoints?</p></li>
<li><p>Does <span class="math inline">\(\mathbf{x}\)</span> explain a large fraction of variation in <span class="math inline">\(y\)</span>?</p></li>
</ul></li>
<li><p>These are the <em>algebraic</em> properties of our estimator</p>
<ul>
<li>Mathematical relationships hold true <em>in each sample</em></li>
</ul></li>
<li><p>Different from the <em>statistical</em> properties</p>
<ul>
<li>The behaviour of estimators across (hypothetical) <em>repeated samples</em></li>
</ul></li>
</ul>
</section>
<section id="properties-of-the-residuals" class="slide level2">
<h2>Properties of the Residuals</h2>
<ul>
<li><p>The first properties relate to the OLS residuals</p>
<p><span class="math display">\[\mathbf{X}'\hat{\mathbf{u}} =
\begin{bmatrix}
\sum_{i=1}^{n}\hat{u}_{i}\\
\sum_{i=1}^{n}x_{1i}\hat{u}_{i}\\
\vdots\\
\sum_{i=1}^{n}x_{ki}\hat{u}_{i}\\
\end{bmatrix}
= \mathbf{0}\]</span></p>
<ul>
<li><p>The sum (and the mean) of the residuals is zero</p></li>
<li><p>The sample covariance between <span class="math inline">\(x\)</span> and the residuals is zero</p></li>
</ul></li>
<li><p>These are the sample versions of <span class="math inline">\(\textbf{E}[\mathbf{x}'\mathbf{u}]=\mathbf{0}\)</span></p>
<ul>
<li>Also come from the first order conditions of OLS</li>
</ul></li>
</ul>
</section>
<section id="r2" class="slide level2">
<h2><span class="math inline">\(R^2\)</span></h2>
<ul>
<li><p>The <strong>Coefficient of Determination (<span class="math inline">\(R^2\)</span>)</strong> measures the fraction of the variation in <span class="math inline">\(y\)</span> that is explained by the independent variables <span class="math display">\[R^2 = \frac{ESS}{TSS}\]</span></p></li>
<li><p>TSS is the <strong>Total Sum of Squares</strong> <span class="math display">\[TSS = \sum_{i=1}^{N} (y_{i} - \bar{y})^2 = \mathbf{(Ny)'Ny} = \mathbf{y'Ny}\]</span></p>
<ul>
<li><p>where <span class="math inline">\(\mathbf{N} = (\mathbf{I} - \frac{1}{n}\mathbf{11'})\)</span> is a symmetric, idempotent matrix</p>
<ul>
<li><span class="math inline">\(\mathbf{1}\)</span> is a vector of all ones</li>
</ul></li>
<li><p><span class="math inline">\(\mathbf{N}\)</span> turns a vector into deviations from means</p></li>
</ul></li>
</ul>
</section>
<section id="r2-1" class="slide level2">
<h2><span class="math inline">\(R^2\)</span></h2>
<ul>
<li><p>ESS is the <strong>Explained Sum of Squares</strong> <span class="math display">\[ESS = \sum_{i=1}^{N} (\hat{y}_{i} - \bar{y})^2 =\mathbf{(N\hat{y})'N\hat{y}} = \mathbf{\hat{y}'N\hat{y}}\]</span></p></li>
<li><p>And the <strong>Residual Sum of Squares (SSR) is</strong> <span class="math display">\[SSR= \sum_{i=1}^{N} (\hat{u}_{i})^2 = \hat{\mathbf{u}}'\hat{\mathbf{u}}\]</span></p></li>
<li><p><span class="math inline">\(R^2\)</span> ranges between 0 and 1</p>
<ul>
<li><p><span class="math inline">\(R^2 = 0\)</span> means that <span class="math inline">\(\mathbf{x}\)</span> explains none of the variation in <span class="math inline">\(y\)</span></p></li>
<li><p><span class="math inline">\(R^2 = 1\)</span> means that <span class="math inline">\(\mathbf{x}\)</span> explains all of the variation in <span class="math inline">\(y\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="r2-2" class="slide level2">
<h2><span class="math inline">\(R^2\)</span></h2>
<ul>
<li><p><span class="math inline">\(R^2\)</span> is also equal to the square of correlation coefficient between <span class="math inline">\(y_{i}\)</span> and <span class="math inline">\(\hat{y}_{i}\)</span></p>
<ul>
<li><span class="math inline">\(R^2 = 1\)</span> is perfect correlation between prediction and actual values</li>
</ul></li>
<li><p>An important relationship between sums of squares is <span class="math display">\[TSS=  ESS + SSR\]</span></p>
<ul>
<li>Movement of <span class="math inline">\(y_{i}\)</span> away from its average is explained by regression and other factors</li>
</ul></li>
<li><p>Using matrix notation,</p>
<p><span class="math display">\[\mathbf{\hat{y}'\mathbf{N}\hat{y}} = (\mathbf{X}\boldsymbol{\hat{\beta}} + \hat{\mathbf{u}})'\mathbf{N}(\mathbf{X}\boldsymbol{\hat{\beta} + \hat{\mathbf{u}}} )\]</span> <span class="math display">\[= (\boldsymbol{\hat{\beta}}' \mathbf{X}'+ \hat{\mathbf{u}}')(\mathbf{N}\mathbf{X}\boldsymbol{\hat{\beta} + \mathbf{N}\hat{\mathbf{u}}} )\]</span> <span class="math display">\[= \boldsymbol{\hat{\beta}}' \mathbf{X}' N\mathbf{X}\boldsymbol{\hat{\beta}} + \boldsymbol{\hat{\beta}}' \mathbf{X}' \mathbf{N}\hat{\mathbf{u}} + \hat{\mathbf{u}}'N\mathbf{X}\boldsymbol{\hat{\beta} +\hat{\mathbf{u}}' \mathbf{N}\hat{\mathbf{u}}}\]</span></p></li>
</ul>
</section>
<section id="r2-3" class="slide level2">
<h2><span class="math inline">\(R^2\)</span></h2>
<ul>
<li><p>Because <span class="math inline">\(\mathbf{N}\hat{\mathbf{u}} =\hat{\mathbf{u}}\)</span> and <span class="math inline">\(\mathbf{X}'\hat{\mathbf{u}} = \mathbf{0}\)</span> we can simplify to</p>
<p><span class="math display">\[= \boldsymbol{\hat{\beta}}' N\mathbf{X}' \mathbf{X}\boldsymbol{\hat{\beta}} +\hat{\mathbf{u}}' \hat{\mathbf{u}} = \mathbf{\hat{y}'N\hat{y}}+\hat{\mathbf{u}}' \hat{\mathbf{u}}\]</span></p></li>
<li><p>We noted above that <span class="math inline">\(ESS = \mathbf{\hat{y}'N\hat{y}}\)</span> and <span class="math inline">\(SSR=\hat{\mathbf{u}}' \hat{\mathbf{u}}\)</span></p></li>
<li><p>As a result, you can reexpress <span class="math display">\[R^2 = \frac{ESS}{TSS} = 1- \frac{SSR}{TSS}\]</span></p></li>
<li><p>Important to be cautious when using <span class="math inline">\(R^2\)</span></p></li>
<li><p>In real applications, <span class="math inline">\(R^2\)</span> is often very low</p>
<ul>
<li><p>Does not mean regression is bad</p></li>
<li><p>Just means we have not captured all factors that explain <span class="math inline">\(Y\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="r2-4" class="slide level2">
<h2><span class="math inline">\(R^2\)</span></h2>
<ul>
<li><p>A low <span class="math inline">\(R^2\)</span> does not imply a poor estimate of <span class="math inline">\(\mathbf{\beta}\)</span></p>
<ul>
<li><p><span class="math inline">\(\mathbf{\beta}\)</span> measures effect on <span class="math inline">\(y\)</span> from changing <span class="math inline">\(\mathbf{x}\)</span>, all else equal</p></li>
<li><p><span class="math inline">\(R^2\)</span> measures fraction of total variation in <span class="math inline">\(y\)</span> is explained by <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>Concepts are independent of each other</p></li>
</ul></li>
<li><p>Whether estimate of <span class="math inline">\(\mathbf{\beta}\)</span> is good or bad depends on statistical properties</p>
<ul>
<li><p>Consistency and unbiasedness</p></li>
<li><p>We cover these in detail below</p></li>
</ul></li>
<li><p>In practice, researchers do not pay much attention to <span class="math inline">\(R^2\)</span></p></li>
</ul>
</section>
<section id="standard-error-of-regression-ser" class="slide level2">
<h2>Standard Error of Regression (SER)</h2>
<ul>
<li><p>Can also measure fit with spread of data around regression line</p></li>
<li><p>The residual <span class="math inline">\(\hat{\mathbf{u}}\)</span> is deviation of <span class="math inline">\(\mathbf{y}\)</span> from prediction <span class="math display">\[\mathbf{\hat{u}} = \mathbf{y} -  \mathbf{X}\boldsymbol{\hat{\beta}}\]</span></p></li>
<li><p>The <strong>standard error of regression (SER)</strong> is the standard deviation of <span class="math inline">\(\hat{u}_{i}\)</span></p>
<ul>
<li>The average distance of <span class="math inline">\(y_{i}\)</span> from its prediction <span class="math inline">\(\hat{y}_{i}\)</span></li>
</ul>
<p><span class="math display">\[SER = s_{\hat{u}} = \sqrt{\frac{\hat{\mathbf{u}}' \hat{\mathbf{u}}}{n-k-1} }= \sqrt{\frac{SSR}{n-k-1} }\]</span></p></li>
</ul>
</section></section>
<section>
<section id="statistical-properties-of-ols-estimator" class="title-slide slide level1 center">
<h1>Statistical Properties of OLS Estimator</h1>

</section>
<section id="introduction-1" class="slide level2">
<h2>Introduction</h2>
<ul>
<li><p><span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> is an estimator for <span class="math inline">\(\boldsymbol{\beta}\)</span></p>
<ul>
<li><p>Just like sample mean is an estimator for population mean</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}\)</span> is a population parameter, <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> is a function of the sample</p></li>
</ul></li>
<li><p>Like all estimators, <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> are random variables with a sampling distribution</p>
<ul>
<li>Realized values change from sample to sample</li>
</ul></li>
<li><p>We want estimators to have certain <em>statistical properties</em></p>
<ul>
<li><p>Consistency</p></li>
<li><p>Efficiency (lowest variance)</p></li>
<li><p>Unbiasedness</p></li>
</ul></li>
</ul>
</section>
<section id="introduction-2" class="slide level2">
<h2>Introduction</h2>
<ul>
<li><p>There are large sample properties and finite sample properties</p>
<ul>
<li><p>Large sample (asymptotic) properties hold as sample size grows large</p></li>
<li><p>Finite sample ones hold in any sample size</p></li>
</ul></li>
<li><p>We will focus most on large sample properties</p>
<ul>
<li><p>Consistency and large sample distribution</p></li>
<li><p>These are often what matter most in applied work</p></li>
<li><p>This will be different from your undergraduate work</p></li>
</ul></li>
<li><p>Occasionally we will also touch on the finite sample properties</p>
<ul>
<li>For example, unbiasedness</li>
</ul></li>
</ul>
</section>
<section id="assumptions" class="slide level2">
<h2>Assumptions</h2>
<ul>
<li><p>To derive the statistical properties, we need some assumptions</p></li>
<li><p>We will focus on the assumptions necessary for the large sample properties</p></li>
</ul>
<ol type="1">
<li><p><span class="math inline">\(\textbf{E}[\mathbf{x}'u]=\mathbf{0}\)</span></p>
<ul>
<li><p>Says that the population residual is mean zero and uncorrelated with <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>This is true in our model by definition, so not really an assumption</p></li>
</ul></li>
<li><p><span class="math inline">\(\text{rank } \textbf{E}[\mathbf{x'x}] = k+1\)</span></p>
<ul>
<li><p>Says that there is no linear dependence in <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>Same as saying there is no <strong>perfect multicollinearity</strong> among regressors</p>
<ul>
<li>None of the <span class="math inline">\(x\)</span> variables are linear functions of another</li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="assumptions-1" class="slide level2">
<h2>Assumptions</h2>
<ol type="1">
<li><p><span class="math inline">\(\{(\mathbf{x}_{i},y_{i}): i=1,2,...,n)\}\)</span> are a random sample</p>
<ul>
<li><p>Implies that the observations are independent and identically distributed (iid)</p></li>
<li><p>This is necessary to establish consistency</p></li>
</ul></li>
</ol>
<ul>
<li><p>Under these three assumptions you can show that <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></p>
<ul>
<li><p>is a consistent estimator for <span class="math inline">\(\boldsymbol{\beta}\)</span></p></li>
<li><p>has a large sample Normal distribution with</p>
<ul>
<li><p>mean <span class="math inline">\(\boldsymbol{\beta}\)</span></p></li>
<li><p>variance <span class="math inline">\(n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\mathbf{E}(u^2\mathbf{x'x})[\mathbf{E}(\mathbf{x'x})^{-1}]\)</span></p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="consistency" class="slide level2">
<h2>Consistency</h2>
<ul>
<li><p><strong>Consistency</strong>:an estimator approaches the parameter when the sample gets big</p>
<ul>
<li>Removing sampling variation leaves us with the true parameter</li>
</ul></li>
<li><p>Econometricians like estimators to be consistent at minimum</p></li>
<li><p>To establish consistency, we need the three assumptions noted above</p>
<ul>
<li><p>Population residual is mean zero and uncorrelated with <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>No linear dependence among <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>Random sampling</p></li>
</ul></li>
</ul>
</section>
<section id="consistency-1" class="slide level2">
<h2>Consistency</h2>
<ul>
<li><p>Mathematically, write the OLS estimator as</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\left (  \mathbf{X'X}\right )^{-1}  \mathbf{X'y}\]</span> <span class="math display">\[=\left (  \mathbf{X'X}\right )^{-1}  \mathbf{X'(X'\boldsymbol{\beta} + u)}\]</span> <span class="math display">\[=\left (  \mathbf{X'X}\right )^{-1}  \mathbf{X'X}\boldsymbol{\beta} + \left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}u\]</span> <span class="math display">\[=\boldsymbol{\beta} + \left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}u\]</span></p></li>
<li><p>If we partition the matrices, we can write this equivalently as</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\boldsymbol{\beta} + \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1} \left (\frac{1}{n}\sum_{i=1}^{n}\mathbf{x_{i}'}u_{i} \right )\]</span></p></li>
<li><p>Consistency means showing <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> approaches <span class="math inline">\(\boldsymbol{\beta}\)</span> as <span class="math inline">\(n\)</span> gets large</p></li>
</ul>
</section>
<section id="consistency-2" class="slide level2">
<h2>Consistency</h2>
<ul>
<li><p>Consistency is established with the probability limit</p>
<ul>
<li><p>Probability that an estimator is in small range around a parameter as <span class="math inline">\(n \rightarrow \infty\)</span></p></li>
<li><p>The probability limit of OLS slope estimator <span class="math inline">\(\hat{\beta}_{k}\)</span> is <span class="math inline">\(\beta_{k}\)</span> if <span class="math display">\[\lim_{n \rightarrow \infty} Pr(\beta_{k} - \epsilon &lt; \hat{\beta}_{k} &lt; \beta_{k} + \epsilon) \rightarrow 1\]</span></p></li>
<li><p>The short form of this is <span class="math display">\[\text{plim }(\hat{\beta}_{k}) = \beta_{k}\]</span></p></li>
</ul></li>
</ul>
</section>
<section id="consistency-3" class="slide level2">
<h2>Consistency</h2>
<ul>
<li>You can use “plim” as an operator with the following rules</li>
</ul>
<p><span class="math display">\[\text{plim}(x+y) = \text{plim}(x) + \text{plim}(y)\]</span> <span class="math display">\[\text{plim}(xy) = \text{plim}(x)\text{plim}(y)\]</span> <span class="math display">\[\text{plim}(\frac{x}{y}) = \frac{\text{plim}(x)}{ \text{plim}(y)}\]</span></p>
</section>
<section id="consistency-4" class="slide level2">
<h2>Consistency</h2>
<ul>
<li>Applying this to our slope estimator</li>
</ul>
<p><span class="math display">\[\text{plim}(\boldsymbol{\hat{\beta}})=\boldsymbol{\beta} + \text{plim} \left( \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1} \left (\frac{1}{n}\sum_{i=1}^{n}\mathbf{x_{i}'}u_{i} \right )\right )\]</span> <span class="math display">\[\text{plim}(\boldsymbol{\hat{\beta}})=\boldsymbol{\beta} + \text{plim} \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1} \text{plim} \left(  \frac{1}{n}\sum_{i=1}^{n}\mathbf{x_{i}'}u_{i} \right )\]</span></p>
</section>
<section id="consistency-5" class="slide level2">
<h2>Consistency</h2>
<ul>
<li><p>You can show that</p>
<p><span class="math display">\[\text{plim} \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1}  = \left( \mathbf{E}[\mathbf{x'x}]\right )^{-1}\]</span> <span class="math display">\[\text{plim} \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x'}u\right )  = \mathbf{E}\left( \mathbf{x'}u\right )\]</span></p></li>
<li><p>A property of our model is <span class="math inline">\(\mathbf{E}\left( \mathbf{x'}u\right ) =\mathbf{0}\)</span>, so</p>
<p><span class="math display">\[\text{plim}(\boldsymbol{\hat{\beta}})=\boldsymbol{\beta}\]</span></p></li>
<li><p>Given our assumptions, the OLS estimator is consistent for <span class="math inline">\(\boldsymbol{\beta}\)</span></p></li>
<li><p>As the sample size gets large, the OLS estimator approaches the true parameter</p></li>
<li><p>Many economic researchers work with big samples, so asymptotic approach works</p></li>
</ul>
</section>
<section id="unbiasedness" class="slide level2">
<h2>Unbiasedness</h2>
<ul>
<li><p>Economists generally think at minimum an estimator should be consistent</p>
<ul>
<li>Estimator should be close to the real value with big samples</li>
</ul></li>
<li><p>Another desirable property is unbiasedness</p>
<ul>
<li>On average, the estimator should equal the parameter</li>
</ul></li>
<li><p>This finite sample property holds for any sample size</p></li>
<li><p>The OLS estimator is unbiased under stricter assumptions than those made above</p></li>
<li><p>We need to replace assumption <span class="math inline">\(\textbf{E}[\mathbf{x}'u]=0\)</span> with <span class="math inline">\(\textbf{E}[u|\mathbf{x}]=0\)</span></p>
<ul>
<li>Assumption says that <span class="math inline">\(u\)</span> is unrelated to <em>any function</em> of <span class="math inline">\(\mathbf{x}\)</span></li>
</ul></li>
</ul>
</section>
<section id="unbiasedness-1" class="slide level2">
<h2>Unbiasedness</h2>
<ul>
<li><p>This is stronger than assuming <span class="math inline">\(\textbf{E}[\mathbf{x}'u]=\mathbf{0}\)</span></p>
<ul>
<li><p>Zero correlation means no linear relationship between <span class="math inline">\(u\)</span> and <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p><span class="math inline">\(\textbf{E}[u|\mathbf{x}]=0\)</span> means no linear or nonlinear relationship</p></li>
</ul></li>
<li><p>With this assumption we can show <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> is unbiased</p></li>
<li><p>Recall the OLS estimator is <span class="math display">\[\boldsymbol{\hat{\beta}}=\boldsymbol{\beta} + \left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}\mathbf{u}\]</span></p></li>
<li><p>We assume <span class="math inline">\(u\)</span> and <span class="math inline">\(\mathbf{x}\)</span> are unrelated in the population, so <span class="math inline">\(\textbf{E}[\mathbf{u}|\mathbf{X}]=\mathbf{0}\)</span></p>
<ul>
<li>Says each element of <span class="math inline">\(\mathbf{u}\)</span> is unrelated to all parts of <span class="math inline">\(\mathbf{X}\)</span></li>
</ul></li>
</ul>
</section>
<section id="unbiasedness-2" class="slide level2">
<h2>Unbiasedness</h2>
<ul>
<li><p>Taking expectations</p>
<p><span class="math display">\[\mathbf{E}[\boldsymbol{\hat{\beta}}|\mathbf{X}]=\mathbf{E}[\boldsymbol{\beta} + \left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}\mathbf{u}|\mathbf{X}]\]</span></p></li>
<li><p>Bringing the expectation operator through the bracket we get</p>
<p><span class="math display">\[\mathbf{E}[\boldsymbol{\hat{\beta}}|\mathbf{X}]=\boldsymbol{\beta} + \mathbf{E}[\left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}\mathbf{u}|\mathbf{X}]\]</span> <span class="math display">\[=\boldsymbol{\beta} + \mathbf{E}[\left (  \mathbf{X'X}\right )^{-1} \mathbf{X'}\mathbf{E}[\mathbf{u}|\mathbf{X}]\]</span> <span class="math display">\[=\boldsymbol{\beta}\]</span></p></li>
<li><p>Says <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> at each <span class="math inline">\(\mathbf{X}\)</span></p></li>
<li><p>If you take the average across all values of <span class="math inline">\(\mathbf{X}\)</span>, you get <span class="math display">\[\mathbf{E}[\boldsymbol{\hat{\beta}}] =\mathbf{E}[\mathbf{E}[\boldsymbol{\hat{\beta}}|\mathbf{X}]] = \boldsymbol{\beta}\]</span></p></li>
</ul>
</section>
<section id="unbiasedness-3" class="slide level2">
<h2>Unbiasedness</h2>
<ul>
<li><p>Important to emphasize unbiasedness requires stronger assumptions</p></li>
<li><p>Some estimators are consistent but biased in finite samples</p>
<ul>
<li><p>Instrumental variables (IV) estimator is one of them</p></li>
<li><p>For this reason only use IV with large samples</p></li>
</ul></li>
<li><p>This is why researchers focus more on consistency as basis for good estimator</p></li>
<li><p>We now discuss the distribution and variance of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></p>
<ul>
<li><p>This will allow us to move on to talking about inference</p></li>
<li><p>We will emphasize that inference is as important as estimation</p></li>
</ul></li>
</ul>
</section>
<section id="large-sample-distribution-of-boldsymbolhatbeta" class="slide level2">
<h2>Large Sample Distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>For doing hypothesis tests on <span class="math inline">\(\boldsymbol{\beta}\)</span>, we need to know the distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></p>
<ul>
<li><p>Need to know where estimate falls in distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> under an assumption about <span class="math inline">\(\boldsymbol{\beta}\)</span></p></li>
<li><p>If our estimate is in the tails of the distribution, we reject</p></li>
<li><p>If it is in the center, we fail to reject</p></li>
</ul></li>
<li><p>We will focus on the large-sample distribution</p>
<ul>
<li><p>Distribution as sample size gets large</p></li>
<li><p>If you make assumptions about the errors, you can get the finite distribution</p></li>
</ul></li>
<li><p>To get large sample distribution, we rely on the <strong>Central Limit Theorem (CLT)</strong></p></li>
</ul>
</section>
<section id="large-sample-distribution-of-boldsymbolhatbeta-1" class="slide level2">
<h2>Large Sample Distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>The CLT says</p>
<ul>
<li><p>Random vectors <span class="math inline">\(w_{i}, i=1,2,...\)</span> are iid with mean <span class="math inline">\(\mathbf{E}(\mathbf{w_{i}})\)</span> and variance <span class="math inline">\(\text{var}(\mathbf{w_{i}})\)</span></p></li>
<li><p>Then <span class="math inline">\(\bar{\mathbf{w}} = \frac{1}{n} \sum_{1=1}^{n}\mathbf{w_{i}}\)</span> converges to <span class="math inline">\(N(\mathbf{E}(\mathbf{w_{i}}), n^{-1}\text{var}(\mathbf{w_{i}}))\)</span></p></li>
</ul></li>
<li><p>If you write the slope estimator as</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\boldsymbol{\beta} + \left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1} \left (\frac{1}{n}\sum_{i=1}^{n}\mathbf{x_{i}'}u_{i} \right )\]</span></p></li>
<li><p>You can see that taking mean of <span class="math inline">\(\boldsymbol{\hat{\beta}}-\boldsymbol{\beta}\)</span> is equivalent to a mean of <span class="math inline">\(\mathbf{x_{i}'}u_{i}\)</span></p></li>
<li><p>Applying the CLT, <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> has a Normal distribution with mean <span class="math inline">\(\boldsymbol{\beta}\)</span> and variance</p>
<p><span class="math display">\[\text{var}(\boldsymbol{\hat{\beta}}) = n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\mathbf{E}(u^2\mathbf{x'x})[\mathbf{E}(\mathbf{x'x})^{-1}]\]</span></p></li>
</ul>
</section>
<section id="large-sample-distribution-of-boldsymbolhatbeta-2" class="slide level2">
<h2>Large Sample Distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>Note that this assumes nothing about the distribution of the error terms</p></li>
<li><p>Sometimes it makes sense to assume <strong>homoskedasticity</strong> of the errors</p>
<ul>
<li>Variation in the errors is not a function of <span class="math inline">\(\mathbf{x}\)</span></li>
</ul></li>
<li><p>Usually this is stated as</p>
<p><span class="math display">\[\text{var}(u|\mathbf{x}) = \sigma^2\]</span></p></li>
<li><p>Note you can write the variance of <span class="math inline">\(u\)</span> given <span class="math inline">\(\mathbf{x}\)</span> as <span class="math display">\[\text{var}(u|\mathbf{x})  = \mathbf{E}(u^2|\mathbf{x}) - \left [ \mathbf{E}(u|\mathbf{x}) \right ]^2\]</span></p>
<ul>
<li>The sum of two conditional expectations</li>
</ul></li>
</ul>
</section>
<section id="large-sample-distribution-of-boldsymbolhatbeta-3" class="slide level2">
<h2>Large Sample Distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>Turns out we only need to assume the first component is constant</p>
<p><span class="math display">\[\mathbf{E}(u^2|\mathbf{x}) = \sigma^2\]</span></p>
<ul>
<li>Means zero covariance between <span class="math inline">\(u^2\)</span> and squares and cross-products of regressors</li>
</ul></li>
<li><p>We can then simplify the expression for <span class="math inline">\(\text{var}(\boldsymbol{\hat{\beta}})\)</span></p></li>
<li><p>First, note that because of the law of iterated expectations</p>
<p><span class="math display">\[\mathbf{E}(u^2\mathbf{x'x}) = \mathbf{E}(\mathbf{E}(u^2|\mathbf{x})\mathbf{x'x})\]</span></p></li>
<li><p>Substituting in <span class="math inline">\(\mathbf{E}(u^2|\mathbf{x}) = \sigma^2\)</span>, we get</p>
<p><span class="math display">\[\mathbf{E}(u^2\mathbf{x'x}) = \sigma^2\mathbf{E}(\mathbf{x'x})\]</span></p></li>
</ul>
</section>
<section id="large-sample-distribution-of-boldsymbolhatbeta-4" class="slide level2">
<h2>Large Sample Distribution of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>Finally, substituting in to the expression for <span class="math inline">\(\text{var}(\boldsymbol{\hat{\beta}})\)</span></p>
<p><span class="math display">\[\text{var}(\boldsymbol{\hat{\beta}}) = n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\sigma^2\mathbf{E}(\mathbf{x'x})[\mathbf{E}(\mathbf{x'x})^{-1}]\]</span> <span class="math display">\[= \sigma^2 n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\mathbf{E}(\mathbf{x'x})[\mathbf{E}(\mathbf{x'x})^{-1}]\]</span> <span class="math display">\[= \sigma^2 n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\]</span></p></li>
<li><p>This is the version of the variance of <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> that is given by default in Stata</p></li>
<li><p>It is only valid under homoskedasticity</p>
<ul>
<li><p>In practice this is rarely the case</p></li>
<li><p>Academic researchers almost never assume homoskedastic errors</p></li>
</ul></li>
<li><p>Note that these are the population variances</p>
<ul>
<li>Based on population moments that we do not know</li>
</ul></li>
</ul>
</section>
<section id="variance-estimator-for-boldsymbolhatbeta" class="slide level2">
<h2>Variance Estimator for <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>Just like we estimated <span class="math inline">\(\beta\)</span>, we must also estimate <span class="math inline">\(\text{var}(\boldsymbol{\hat{\beta}})\)</span></p></li>
<li><p>Follow the same procedure by replacing population moments with sample ones</p>
<p><span class="math display">\[\text{var}(\boldsymbol{\hat{\beta}}) = n^{-1}[\mathbf{E}(\mathbf{x'x})^{-1}]\mathbf{E}(u^2\mathbf{x'x})[\mathbf{E}(\mathbf{x'x})^{-1}]\]</span> <span class="math display">\[\hat{\text{var}}(\boldsymbol{\hat{\beta}}) = n^{-1}\left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1}\left ( \frac{1}{n} \sum_{i=1}^{n}\hat{u}_{i}^2\mathbf{x_{i}'x_{i}}\right )\left ( \frac{1}{n} \sum_{i=1}^{n}\mathbf{x_{i}'x_{i}}\right )^{-1}\]</span></p>
<p><span class="math display">\[\hat{\text{var}}(\boldsymbol{\hat{\beta}}) = \left (\mathbf{X'X}\right )^{-1}\left ( \sum_{i=1}^{n}\hat{u}_{i}^2\mathbf{x_{i}'x_{i}}\right )\left ( \mathbf{X'X}\right )^{-1}\]</span></p></li>
<li><p>This is the <strong>Heteroskedasticity-Robust</strong> estimator of the variance</p>
<ul>
<li>Sometimes just called the robust estimator</li>
</ul></li>
</ul>
</section>
<section id="variance-estimator-for-boldsymbolhatbeta-1" class="slide level2">
<h2>Variance Estimator for <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></h2>
<ul>
<li><p>It is what Stata produces when you use the “robust” option in regression</p></li>
<li><p>The square root of the diagonal elements are the <strong>Robust Standard Errors</strong></p></li>
<li><p>If we assume homoskedastic errors, we get</p>
<p><span class="math display">\[\hat{\text{var}}(\boldsymbol{\hat{\beta}}) = s_{\hat{u}}^2 \left (\mathbf{X'X}\right )^{-1}\]</span></p></li>
<li><p>where <span class="math inline">\(s_{\hat{u}}^2\)</span> is a consistent estimator of <span class="math inline">\(\sigma^2\)</span> and equals</p>
<p><span class="math display">\[s_{\hat{u}}^2 = \frac{\hat{\mathbf{u}}'\hat{\mathbf{u}}}{n-k-1}\]</span></p></li>
<li><p>The square root of the diagonals are Stata’s default standard errors</p></li>
</ul>
</section></section>
<section>
<section id="hypothesis-testing" class="title-slide slide level1 center">
<h1>Hypothesis Testing</h1>

</section>
<section id="introduction-3" class="slide level2">
<h2>Introduction</h2>
<ul>
<li><p>Recall that we will never know the value of the true slope parameters</p>
<ul>
<li>This is why we are estimating it</li>
</ul></li>
<li><p>But, we can use our estimator and estimate to test hypotheses about them</p></li>
<li><p>Procedure is as follows</p>
<ul>
<li><p>Make tentative assumption about true slope</p></li>
<li><p>Choose a test statistic, with known distribution under assumption</p></li>
<li><p>Formulate a decision rule</p></li>
<li><p>Check whether estimate is likely to occur under that rule</p>
<ul>
<li><p>If no, then reject</p></li>
<li><p>If yes, fail to reject</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="testing-single-linear-hypotheses" class="slide level2">
<h2>Testing Single Linear Hypotheses</h2>
<ul>
<li><p>Often in applied econometrics we test hypotheses about one parameter</p>
<ul>
<li><p>Usually we are interested in effect of one of regressors on outcome</p></li>
<li><p>We test whether that slope parameter is zero</p></li>
</ul></li>
<li><p>The standard method is to use a <span class="math inline">\(t\)</span>-test</p></li>
<li><p>In the linear regression model, the null and alternative hypotheses are</p>
<ul>
<li><p><span class="math inline">\(H_{0}: \beta_{j} = \beta_{j,0}\)</span></p></li>
<li><p><span class="math inline">\(H_{1}: \beta_{j} \neq \beta_{j,0}\)</span></p></li>
</ul></li>
<li><p>The test statistic is the <span class="math inline">\(t\)</span> statistic</p>
<p><span class="math display">\[t=\frac{\hat{\beta}_{j} - \beta_{j,0}}{se(\hat{\beta}_{j} )}\]</span></p></li>
</ul>
</section>
<section id="testing-single-linear-hypotheses-1" class="slide level2">
<h2>Testing Single Linear Hypotheses</h2>
<ul>
<li><p>The <span class="math inline">\(t\)</span>-statistic is a random variable that varies across samples</p></li>
<li><p>It has a Standard Normal distribution in large samples</p>
<ul>
<li>It is a standardized version of a Normal random variable</li>
</ul></li>
<li><p>To compute the <span class="math inline">\(t\)</span>-statistic, we need <span class="math inline">\(se(\hat{\beta}_{j} )\)</span></p>
<ul>
<li><p>This is the square root of the <span class="math inline">\(j\)</span>th diagonal element of <span class="math inline">\(\hat{\text{var}}(\boldsymbol{\hat{\beta}})\)</span></p></li>
<li><p>The formula we use for <span class="math inline">\(\hat{\text{var}}(\boldsymbol{\hat{\beta}})\)</span> depends on whether we assume homoskedasticity</p></li>
</ul></li>
<li><p>We then make a decision rule for rejection</p>
<ul>
<li><p>Usually this is defined in terms of a <strong>Significance Level</strong></p>
<ul>
<li>The significance level <span class="math inline">\(\alpha\)</span> is the maximum proportion of all possible <span class="math inline">\(t\)</span> values unusual enough to reject <span class="math inline">\(H_{0}\)</span></li>
</ul></li>
<li><p>Typically, this is <span class="math inline">\(\alpha = 0.05\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="testing-single-linear-hypotheses-2" class="slide level2">
<h2>Testing Single Linear Hypotheses</h2>
<ul>
<li><p>Choice of significance level divides sampling distribution into two regions</p>
<ul>
<li><p>Rejection Region: values for <span class="math inline">\(t\)</span> where we reject <span class="math inline">\(H_{0}\)</span></p>
<ul>
<li><p>One-sided test: the upper or lower <span class="math inline">\(\alpha \%\)</span> of values</p></li>
<li><p>Two-sided test: the upper and lower <span class="math inline">\(\frac{\alpha}{2} \%\)</span> of values</p></li>
</ul></li>
<li><p>Acceptance Region: values for <span class="math inline">\(t\)</span> where we accept <span class="math inline">\(H_{0}\)</span></p>
<ul>
<li><p>One-sided test: the upper or lower <span class="math inline">\((1-\alpha) \%\)</span> of values</p></li>
<li><p>Two-sided test: the middle <span class="math inline">\((1-\alpha) \%\)</span> of values</p></li>
</ul></li>
</ul></li>
<li><p>The <strong>Critical Value</strong> separates the acceptance and rejection regions</p>
<ul>
<li><p>On graphs below it is value between green and white regions</p></li>
<li><p>For two-tailed tests, there are two critical values</p></li>
</ul></li>
</ul>
</section>
<section id="testing-single-linear-hypotheses-3" class="slide level2">
<h2>Testing Single Linear Hypotheses</h2>
<p><img data-src="uptail.png" style="width:4.3in" alt="image"> <img data-src="lowtail.png" style="width:4.3in" alt="image"><br>
<img data-src="twotail.png" style="width:4.3in" alt="image"></p>
</section>
<section id="testing-single-linear-hypotheses-4" class="slide level2">
<h2>Testing Single Linear Hypotheses</h2>
<ul>
<li><p>Value depends on sampling distribution and <span class="math inline">\(\alpha\)</span></p>
<ul>
<li><p>At <span class="math inline">\(5\%\)</span> significance with a t-distribution and a large sample</p>
<ul>
<li><p>Upper tailed test: <span class="math inline">\(t^{c}\)</span> = 1.64</p></li>
<li><p>Lower tailed test: <span class="math inline">\(t^{c}\)</span> = -1.64</p></li>
<li><p>Two tailed test: <span class="math inline">\(|t^{c}|\)</span> = 1.96</p></li>
</ul></li>
</ul></li>
<li><p>Finally, we compare our realized test statistic to the critical values</p>
<ul>
<li><p>In two-tailed test reject if <span class="math inline">\(|t| &gt; |t^{c}|\)</span></p></li>
<li><p>In lower-tailed test reject if <span class="math inline">\(t &lt; t^{c}\)</span></p></li>
<li><p>In upper-tailed test reject if <span class="math inline">\(t &gt; t^{c}\)</span></p></li>
</ul></li>
<li><p>If you do not reject, you fail to reject</p>
<ul>
<li>Not the same as accepting the null hypothesis</li>
</ul></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>Sometimes you need to test multiple hypotheses at the same time</p>
<ul>
<li><p>Testing significance of the model</p></li>
<li><p>Testing whether two parameters are equal</p></li>
</ul></li>
<li><p>We follow a similar procedure</p>
<ul>
<li><p>Make tentative assumption about parameters</p></li>
<li><p>Choose a test statistic with known distribution</p></li>
<li><p>Make decision rule</p></li>
<li><p>Compute test statistic and apply decision rule</p></li>
</ul></li>
<li><p>Key difference is in the test statistic we use</p></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses-1" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>We can write multiple hypotheses with matrix notation</p>
<p><span class="math display">\[H_{0}: \mathbf{R}\boldsymbol{\beta} =\mathbf{r}\]</span> <span class="math display">\[H_{1}: \mathbf{R}\boldsymbol{\beta} \neq \mathbf{r}\]</span></p>
<ul>
<li><p><span class="math inline">\(\mathbf{R}\)</span> is a <span class="math inline">\(q \times k+1\)</span> matrix of constants</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\(k+1 \times 1\)</span> vector of slope parameters</p></li>
<li><p><span class="math inline">\(r\)</span> is a <span class="math inline">\(q \times 1\)</span> vector of constants</p></li>
</ul></li>
<li><p>For example, suppose you want to test <span class="math inline">\(H_{0}: \beta_{2} = 0\)</span>. In this case</p>
<p><span class="math display">\[\mathbf{R} =
\begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0
\end{bmatrix}\]</span> <span class="math display">\[r = 0\]</span></p></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses-2" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>If you multiply this out you get</p>
<p><span class="math display">\[\mathbf{R}\boldsymbol{\beta} =
\begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0
\end{bmatrix}
\begin{bmatrix}
\beta_{0}\\
\beta_{1}\\
\beta_{2} \\
\vdots\\
\beta_{k}
\end{bmatrix}
=\beta_{2}\]</span></p></li>
<li><p>So that <span class="math inline">\(\mathbf{R}\boldsymbol{\beta} =r\)</span> is equivalent to <span class="math inline">\(\beta_{2} = 0\)</span></p></li>
<li><p>Now imagine you want to test <span class="math inline">\(H_{0}: \beta_{2} = 0, \beta_{4} = 2\)</span></p>
<p><span class="math display">\[\mathbf{R} =
\begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 0 &amp;0&amp;\cdots &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp;1&amp;\cdots &amp; 0
\end{bmatrix}\]</span> <span class="math display">\[\mathbf{r} =
\begin{bmatrix}
0 \\
2
\end{bmatrix}\]</span></p></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses-3" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>If you multiply out in this case</p>
<p><span class="math display">\[\mathbf{R}\boldsymbol{\beta} =
\begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 0 &amp;0&amp;\cdots &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp;1&amp;\cdots &amp; 0
\end{bmatrix}
\begin{bmatrix}
\beta_{0}\\
\beta_{1}\\
\beta_{2} \\
\vdots\\
\beta_{k}
\end{bmatrix}
=
\begin{bmatrix}
\beta_{2}\\
\beta_{4}
\end{bmatrix}\]</span></p></li>
<li><p>So that <span class="math inline">\(\mathbf{R}\boldsymbol{\beta} =r\)</span> is equivalent to <span class="math display">\[\begin{bmatrix}
\beta_{2}\\
\beta_{4}
\end{bmatrix}
=
\begin{bmatrix}
0\\
2
\end{bmatrix}\]</span></p></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses-4" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>When testing multiple linear restrictions, it is common to use the <strong>Wald Statistic</strong></p>
<p><span class="math display">\[W = (\mathbf{R}\boldsymbol{\hat{\beta}} -\mathbf{r} )'(\mathbf{R}\hat{\text{var}}(\boldsymbol{\hat{\beta}})  \mathbf{R}')^{-1} (\mathbf{R}\boldsymbol{\hat{\beta}} -\mathbf{r} )\]</span></p>
<ul>
<li><p>Intuition is <span class="math inline">\(W\)</span> computes squared distance between estimate and null hypothesis</p></li>
<li><p>Distance is scaled by the variance</p></li>
<li><p>If that distance is too far, we reject the null</p></li>
<li><p>Very similar to intuition of <span class="math inline">\(t\)</span>-test</p></li>
</ul></li>
<li><p><span class="math inline">\(\text{var}(\boldsymbol{\hat{\beta}})\)</span> is variance matrix of OLS estimator computed above</p>
<ul>
<li>Use Robust or Homoskedastic version as appropriate</li>
</ul></li>
</ul>
</section>
<section id="testing-multiple-linear-hypotheses-5" class="slide level2">
<h2>Testing Multiple Linear Hypotheses</h2>
<ul>
<li><p>Note that you can test single restrictions this way</p></li>
<li><p>Suppose you are testing <span class="math inline">\(\beta_{2} = 0\)</span>. The <span class="math inline">\(W\)</span> statistic reduces to</p></li>
</ul>
<p><span class="math display">\[W = \frac{(\hat{\beta}_{2} - 0)^2}{\text{var}(\hat{\beta}_{2})}\]</span></p>
<ul>
<li><p>The <span class="math inline">\(W\)</span> statistic has a <span class="math inline">\(\chi^2_{q}\)</span> distribution in large samples</p></li>
<li><p>In Stata, this is sometimes implemented as an <span class="math inline">\(F\)</span>-test, where</p>
<p><span class="math display">\[F = \frac{W}{q}\]</span></p></li>
<li><p><span class="math inline">\(F\)</span> has an <span class="math inline">\(F\)</span> distribution with <span class="math inline">\((1,n-k-1)\)</span> degrees of freedom</p></li>
</ul>
<div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="ols_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="ols_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="ols_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="ols_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="ols_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="ols_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="ols_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="ols_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="ols_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="ols_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="ols_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"whiteboard","src":"drawings.json"},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>