\documentclass[aspectratio=169]{beamer}
\usefonttheme[onlymath]{serif}
\usepackage{amsmath}
\usepackage{color}
\usepackage{verbatim}
\usepackage{xyling}
\usepackage{pgf,pgfarrows,pgfnodes}
\usepackage{natbib}
\usepackage{amsmath}
\def\newblock{\hskip .11em plus .33em minus .07em}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\mmin}{min}
\DeclareMathOperator*{\llim}{lim}


 \title{EC 655\\Panel Data}
\author{Justin Smith}
\date{Fall 2021}

\begin{document}

\frame{
\titlepage
}


\frame{
\frametitle{Panel Data}
\begin{block}{Introduction}
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 
\item Repeated observations of some individual unit along some dimension
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 
\item Typically, observing same people/firms/countries over time
\item Second dimension does not have to be time
\end{itemize}
\item Panel data can be used in several ways
\begin{enumerate}
\item Deal with individual heterogeneity
\item Increase variation (reduce standard errors)
\item Study dynamics
 \end{enumerate}
 \item In microeconometrics, panel data mostly controls for individual heterogeneity
 \item We will study
 \begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip}

 \item Basic panel data methods
 \item Using panel data to identify parameters
 \end{itemize}
 \end{itemize}
\end{block}

}


\frame{
\frametitle{Panel Data Basics}
\begin{block}{Structure of Panel Data}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Panels have at least 2 dimensions

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Variation occurs over $i$ and $j$
\item To fix ideas $i=1,\ldots,N$ people, and $j=1,\ldots,J$ time
\end{itemize}
 
\item A \textbf{balanced} panel is one where all individuals are observed in every time period
\item An \textbf{unbalanced} panel has at least one person not observed in a time period
 \end{itemize}
\vspace{-0.4cm}
\begin{small}
\begin{columns}[onlytextwidth,c]
				\begin{column}{0.4\textwidth}
 \begin{table}[htbp]
    %\topcaption{Table captions are better up top} % requires the topcapt package
    \begin{tabular}{ccc} % Column formatting, @{} suppresses leading/trailing space
 	ID & Year & Income \\
	1 & 1990 & 60000\\
		1 & 1991 & 65000\\
	1 & 1992 & 90000\\
	2 & 1990 & 20000\\
		2 & 1991 & 21000\\
	2 & 1992 & 24000\\
    \end{tabular}
    \caption{Balanced Panel}
     \end{table}
\end{column}
				\begin{column}{0.4\textwidth}
 \begin{table}[htbp]
        \begin{tabular}{ccc} % Column formatting, @{} suppresses leading/trailing space
 	ID & Year & Education \\
	1 & 1990 & 60000\\
 	1 & 1991 & 90000\\
	2 & 1990 & 20000\\
		2 & 1991 & 21000\\
	2 & 1992 & 24000\\
    \end{tabular}
    \caption{Unbalanced Panel}
 \end{table}
 \end{column}
 \end{columns}
 \end{small}
\end{block}

}




\frame{
\frametitle{Panel Data Basics}
\begin{block}{Unobserved Effects Model}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Model for panel data adjusts regular regression model with unobserved variable that only varies over individuals


\item The regression model is
\[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +a_{i} + u_{ij}  \]

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item $\mathbf{x_{ij}}$ contains a constant
\item $a_{i}$ is the unobserved effect
\end{itemize}
\item Assume we are not interested in the effect of $a_{i}$ on $y_{ij}$

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Usually it is not observed, or unmeasurable anyway
\item This is why it is not written with a parameter
\end{itemize}
\item Several models we can use to estimate the parameters $\boldsymbol{\beta}$

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Depends on assumption about relationship between $\mathbf{x_{ij}}$ and $a_{i}$
\end{itemize}
\end{itemize}
\end{block}

}

\frame{
\frametitle{Panel Data Basics}
\begin{block}{Strict Exogeneity}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item We learned regression model was structural when error was mean independent
\item Panel model is structural when we assume \textbf{Strict Exogeneity}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 


\item Error term $u_{ij}$ has zero mean conditional on $a_{i}$ and $\mathbf{x_{ij}}$ in \emph{all time periods}.

\end{itemize}

 \item Mathematically, strict exogeneity is written as
 \[ E[u_{ij} | \mathbf{x_{i1}}, \mathbf{x_{i2}}, \ldots, \mathbf{x_{iJ}}, a_{i}] =0\]
 \item It implies that $u_{ij}$ in each time period is uncorrelated with $\mathbf{x_{ij}}$ in each time period
  \[ E[\mathbf{x_{is}^{'}}u_{ij}] =0, \forall s,j = 1,2,\ldots, J\]

 \end{itemize}
\end{block}

}


\frame{
\frametitle{Panel Data Basics}
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item It also implies that the unobserved effect is uncorrelated with $u_{ij}$ in every time period
  \[ E[a_{i}u_{is}] =0, \forall s = 1,2,\ldots, J\]


\item Strict exogeneity assumptions are necessary for consistency of estimators we discuss below


\item Note that strict exogeneity says nothing about the correlation between $\mathbf{x_{ij}}$ and $a_{i}$ 

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item We must make an additional assumption
\item It is this assumption that determines what model we use 
\end{itemize}
 \end{itemize}
}



\frame{
\frametitle{Panel Data Estimation Techniques}
\begin{block}{Fixed Effects}
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item If we assume $\mathbf{x_{ij}}$ and $a_{i}$ are \emph{correlated}, then fixed effects is the appropriate method
\[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +a_{i} + u_{ij}  \]
\item This is the most popular panel data method

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Main use of panel data is to account for an unobserved factors correlated with $\mathbf{x_{ij}}$
\item In this case, we assume the unobserved factor is \emph{time constant}
\end{itemize}
\item Fixed effects is a method to remove the influence of $a_{i}$ to get estimates of $\boldsymbol{\beta}$
\item There are two main ways to estimate a fixed model
 \end{itemize}

 \end{block}
}


\frame{
\frametitle{Panel Data Estimation Techniques}
  
  \begin{enumerate}
\item ``Within'' Transformation

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Find the average of each variable \emph{within the cross-sectional unit}
\[\bar{y}_{i} =  \mathbf{\bar{x}_{i}}\boldsymbol{\beta} +a_{i} + \bar{u}_{i}  \]
\end{itemize}
  
  
 

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Then subtract the within unit mean from each observation
\[ y_{ij} - \bar{y}_{i} = (\mathbf{x_{ij}} - \mathbf{\bar{x}_{i}})\boldsymbol{\beta} + a_{i} - a_{i} + u_{ij} - \bar{u}_{i} \]
\[ y_{ij} - \bar{y}_{i} = (\mathbf{x_{ij}} - \mathbf{\bar{x}_{i}})\boldsymbol{\beta}   + u_{ij} - \bar{u}_{i} \]
\[ y_{ij}^{*} = \mathbf{x_{ij}}^{*}\boldsymbol{\beta}   + u_{ij}^{*}  \]
\item Since $a_{i}$ does not vary across $j$, its cross-sectional unit mean is $a_{i}$ and it is eliminated when we subtract the means
\item If we estimate the equation above by OLS, we get the Fixed Effects Estimator
\[ \boldsymbol{\hat{\beta}_{fe}} = \mathbf{(X^{*'} X^{*})^{-1}X^{*'} Y^{*}}\]
\item The matrix $\mathbf{X^{*}}$ contains all observations over time and persons and is $(N\times J)$ by $K$

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item It is easiest to think of them as stacked cross-sectional observations
\end{itemize}
 \end{itemize}
 \end{enumerate} 

   }
  
  \frame{
\frametitle{Panel Data Estimation Techniques}
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item For each cross-sectional observation we have
 \[ \mathbf{X_{i}} = \begin{bmatrix} x_{i1}^{1}  &x_{i1}^{2}&\ldots &x_{i1}^{K}\\ 
							x_{i2}^{1} &x_{i2}^{2}&\ldots &x_{i2}^{K} \\
							\vdots &\ddots & \ldots & \vdots \\
							x_{iJ}^{1}&x_{iJ}^{2}&\ldots &x_{iJ}^{K} \\
							\end{bmatrix} ,  \mathbf{\bar{X}_{i}}  =\begin{bmatrix} \bar{x_{i}}^{1}  &\bar{x_{i}}^{2}&\ldots &\bar{x_{i}}^{K}\\ 
							\bar{x_{i}}^{1}  &\bar{x_{i}}^{2}&\ldots &\bar{x_{i}}^{K} \\
							\vdots &\ddots & \ldots & \vdots \\
							\bar{x_{i}}^{1}  &\bar{x_{i}}^{2}&\ldots &\bar{x_{i}}^{K} \\
							\end{bmatrix} \]  
\[ \mathbf{X^{*}_{i}} = \begin{bmatrix} (x_{i1}^{1} - \bar{x}_{i}^{1}) &(x_{i1}^{2}-\bar{x}_{i}^{2})&\ldots &(x_{i1}^{K}-\bar{x}_{i}^{K})\\ 
							(x_{i2}^{1}-\bar{x}_{i}^{1}) &(x_{i2}^{2}-\bar{x}_{i}^{2})&\ldots &(x_{i2}^{K}-\bar{x}_{i}^{K}) \\
							\vdots &\ddots & \ldots & \vdots \\
							(x_{iJ}^{1} -\bar{x}_{i}^{1})&(x_{iJ}^{2}-\bar{x}_{i}^{2})&\ldots &(x_{iJ}^{K}-\bar{x}_{i}^{K}) \\
							\end{bmatrix} =  \mathbf{X_{i}}  - \mathbf{\bar{X}_{i}} \]

\item These matrices are then stacked on top of each other
\[ \mathbf{X^{*}} = \begin{bmatrix} \mathbf{X^{*}_{1}} \\ \mathbf{X^{*}_{2}} \\ \vdots \\ \mathbf{X^{*}_{N}}  \end{bmatrix} \]

\end{itemize}

}



  \frame{
\frametitle{Panel Data Estimation Techniques}
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item The fixed effects estimator can be derived using the \emph{time-demeaning matrix}
  \item Let $\mathbf{i}$ be a $J \times 1$ column of ones
  \item Define the $J \times J$ matrix $\mathbf{M_{0}}$ as one that turns the columns of any matrix with $J$ rows into deviations from means
  \[ \mathbf{M_{0}} = \mathbf{I}_{J} - \frac{1}{J}\mathbf{ii'} \]
\item Next, define the following $NJ \times NJ$ matrix $\mathbf{M_{D}}$ 
\[  \mathbf{M_{D}}  = \begin{bmatrix} \mathbf{M_{0}} & 0 & \ldots &0\\
							   0 & \mathbf{M_{0}}& \ldots &0 \\
							   \vdots &\ddots & \ldots & \vdots \\
							   0 & 0& \ldots & \mathbf{M_{0}}   \\
							\end{bmatrix}   \]
\item The Fixed Effects estimator can be written as
\[ \boldsymbol{\hat{\beta}_{fe}} = \mathbf{(X^{'}M_{D}X)^{-1}X^{'}M_{D} Y}\]

\end{itemize}

}

  \frame{
\frametitle{Panel Data Estimation Techniques}
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item The robust estimator for the variance covariance matrix for $\boldsymbol{\hat{\beta}_{fe}}$ is 
\[\hat{var}(\boldsymbol{\hat{\beta}_{fe}})= \mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}} \left ( \sum_{i=1}^{n} \mathbf{X^{*'}_{i} \hat{u}_{i}^{*} \hat{u}_{i}^{*'}X^{*}_{i}}\right ) \mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}}\]

  
  
\item This estimator is robust to both heteroskedasticity and serial correlation

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Serial correlation is an issue because the data have a time element
\item Heteroskedasticity can happen because the data have a cross-sectional element
\end{itemize}


\item If you are willing to assume zero heteroskedasticity and serial correlation, you can simplify this variance estimator
\end{itemize}

}

  \frame{
\frametitle{Panel Data Estimation Techniques}
   \begin{enumerate}
   \setcounter{enumi}{1}
  \item A second estimation method is the \textbf{Dummy Variable Regression}
  \end{enumerate}
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item In this model, we include a dummy variable for each cross-sectional unit
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item The interpretation of $a_{i}$ changes
  \item It is now considered a parameter and not a variable
  \item In practice, it does not matter, as both the DVR and Fixed Effects Estimator produce the same results for the slope estimator
  \end{itemize}
  \item The regression is
  \[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} + \mathbf{D_{i}}\boldsymbol{\alpha} + u_{ij}  \]
 \item Where $D_{i}$ is a vector of dummy variables indicating the cross-sectional unit, and $\alpha$ is an $N-1$ vector (we exclude 1 of the dummies to identify the model)
  \item The vector $\boldsymbol{\hat{\beta}_{DVR}}$ will be identical to $\boldsymbol{\hat{\beta}_{fe}}$

\end{itemize}

}


  \frame{
\frametitle{Panel Data Estimation Techniques}
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item For a couple of reasons we usually do not use the DVR approach
  \begin{enumerate}
  \item If $N$ is large, it takes forever to estimate
  \item We do not care about $a_{i}$ normally
  \item The estimator is not consistent as $N \rightarrow \infty$
   \end{enumerate}
   \item With the DVR approach, you would use the variance estimator we discussed in the OLS section
\begin{block}{Important Considerations For Fixed Effects Models}
 
\item It uses only variation \emph{within cross-sectional units} to identify parameters

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Variables must have variance over time, or else they are eliminated
\item Variables that do not have much variance over time will have big standard errors
 \end{itemize}
\end{block}
\end{itemize}

}



  \frame{
\frametitle{Panel Data Estimation Techniques}
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item Fixed effects is frequently used to infer causality
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item Unobserved variables are ``controlled'' with the fixed effect
   \item This is \emph{only} appropriate if all unobserved heterogeneity is constant over time
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item If unobserved variables differ over time, no causality can be inferred
   \end{itemize}
   \end{itemize}
\end{itemize}



   \begin{block}{First Differencing}
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item In this method, we still assume $\mathbf{x_{ij}}$ and $a_{i}$ are \emph{correlated}
   \item The estimating equation is
   \[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +a_{i} + u_{ij}  \]
\item Imagine lagging this equation by 1 time period
   \[y_{ij-1} =  \mathbf{x_{ij-1}}\boldsymbol{\beta} +a_{i} + u_{ij-1}  \]
\end{itemize}
   \end{block}
}


  \frame{
\frametitle{Panel Data Estimation Techniques}
 
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item Then difference the equations
      \[y_{ij} -  y_{ij-1} =  \mathbf{(x_{ij} -x_{ij-1}) }\boldsymbol{\beta} +a_{i}-a_{i} + u_{ij} -u_{ij-1} \]
      \[\Delta y_{ij}=  \mathbf{(\Delta x_{ij}  ) }\boldsymbol{\beta}   + \Delta u_{ij}  \]
\item Since $a_{i}$ is constant over time for each cross-sectional unit, it is eliminated when we difference
\item The amount of data we have left after differencing depends on the number of time periods

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item If T = 2, then we are left with 1 observation per person
\item If T = 3, then we are left with 2 observations per person
\item etc...
\end{itemize}
\item The first difference estimator is the OLS estimator applied to the differenced data

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Collecting $y_{ij}$ and $\mathbf{x_{ij}}$ into matrices, we get
\[\boldsymbol{\hat{\beta}_{fd}} = \mathbf{((\Delta X)^{'}(\Delta X))^{-1}(\Delta X)^{'}(\Delta Y)} \]
\end{itemize}
\end{itemize}
 }
 
 
 
   \frame{
\frametitle{Panel Data Estimation Techniques}
 
   
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

   \item The robust variance covariance matrix for $\boldsymbol{\beta_{fd}} $ is
   
   \[\hat{var}(\boldsymbol{\hat{\beta}_{fd}}) = \mathbf{(\Delta X' \Delta X)^{-1}} \left ( \sum_{i=1}^{n} \mathbf{\Delta X'_{i} \Delta\hat{u}_{i} \Delta\hat{u}'_{i}\Delta X_{i}}\right ) \mathbf{(\Delta X' \Delta X)^{-1}}\]


\item Again this is robust to both heteroskedasticity and serial correlation
\end{itemize}
\begin{block}{Important Considerations For First Difference Models}
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item There must be variation in a variable over time for it to be included
 
\item To infer a causal relationship, the unobserved heterogeneity must be time constant
\end{itemize}
\end{block}
 }
 
 
 
    \frame{
\frametitle{Panel Data Estimation Techniques}
 
\begin{block}{Random Effects}
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item In random effects we assume $\mathbf{x_{ij}}$ and $a_{i}$ are \emph{uncorrelated}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Thus, random effects is NOT an identification strategy
\item It forces $a_{i}$ into the error term
\item Putting $a_{i}$ into the error term implies a specific error structure
\end{itemize}
\item The model is still
   \[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +a_{i} + u_{ij}  \]
\item Except now we force $a_{i}$ into the error
   \[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +v_{ij}  \]
   \[v_{ij} = a_{i} + u_{ij}  \]
   \item Implies a ``block correlation'' in errors across $i$
  
 \end{itemize}
\end{block}
 }
 
 
 
     \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item The random effects model attempts to harness this block correlation
\item The method imposes certain assumptions on the data (in addition to strict exogeneity)
\begin{enumerate}
 \item $E(u_{ij}^2) = \sigma_{u}$ (homoskedasticity)
\item $E(u_{ij}u_{is}) = 0, \forall j \neq s$ (no serial correlation)
\end{enumerate}
\item Strict exogeniety implies $E(a_{i}u_{ij}) =0, \forall t$
\item Under these assumptions

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item The diagonal elements of the variance covariance matrix for person $i$ are
\[ E(v_{ij}^{2}) = E(a_{i}^{2}) + 2E(a_{i}u_{ij}) + E(u_{ij}^{2}) = \sigma_{a} + \sigma_{u}  \]
\end{itemize}

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item The off-diagonal elements of the variance covariance matrix for person $i$ are
\[ E(v_{ij}v_{is}) = E[(a_{i} - u_{ij})(a_{i} - u_{ij})] = E(a_{i}^{2}) = \sigma_{a} \]
\end{itemize}

 \end{itemize}
  }
  
  
       \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item If we group all observations for person $i$ into a matrix, then
 
 \[\boldsymbol{\Sigma} =  E(\mathbf{v_{i}v_{i}'}) =   \begin{bmatrix} \sigma_{a} + \sigma_{\epsilon}&  \sigma_{a}  & \ldots &  \sigma_{a}\\
							     \sigma_{a} & \sigma_{a} + \sigma_{\epsilon}& \ldots & \sigma_{a} \\
							   \vdots &\ddots & \ldots & \vdots \\
							    \sigma_{a} &  \sigma_{a}& \ldots & \sigma_{a} + \sigma_{\epsilon} \\
							\end{bmatrix}   \]
\item The variance covariance matrix of the errors for the whole data set is
 \[\boldsymbol{\Omega} =     \begin{bmatrix} \boldsymbol{\Sigma}& \mathbf{0}  & \ldots & \mathbf{0}\\
							     \mathbf{0}& \boldsymbol{\Sigma}& \ldots & \mathbf{0} \\
							   \vdots &\ddots & \ldots & \vdots \\
							   \mathbf{0}&  \mathbf{0}& \ldots & \boldsymbol{\Sigma}\\
							\end{bmatrix}   \]
\item This is the ``random effects structure''

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Errors are correlated within $i$, but not across $i$

\end{itemize}
 \end{itemize}
  }
  
  
         \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item The random effects estimator is GLS applied to the data using the random effects error structure
 
 \item GLS ``transforms'' the data, and runs OLS on the transformed data
 \item The random effects estimator is
 \[ \boldsymbol{\hat{\beta}_{re}} =  \mathbf{(X' \hat{\Omega}^{-1}X)^{-1}X'\hat{\Omega}^{-1}Y} \]
 \item $\boldsymbol{\hat{\Omega}}$ is the estimated variance covariance matrix with $\sigma_{u}$ and   $\sigma_{a} $ replaced by estimates
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item Note that for $\boldsymbol{\hat{\beta}_{re}}$ to be efficient, we must make stronger assumptions than before
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item $E(u_{ij}^2|\mathbf{x_{i}}, a_{i}) = \sigma_{\epsilon}$ 
\item $E(u_{ij}u_{is}|\mathbf{x_{i}}, a_{i}) = 0, \forall j \neq s$
  \item $E(a_{i}^2|\mathbf{x_{i}}) = \sigma_{a}$ 
\end{itemize}
 \end{itemize}
  \end{itemize}
  }
  
  
           \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item We need a consistent estimates of $\sigma_{\epsilon}$ and   $\sigma_{a}$
 \item To do so, we follow the method of Wooldridge (2002)
 
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

 \item Recall that 
     \[y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +v_{ij}  \]
   \[v_{ij} = a_{i} + u_{ij}  \]
   \item Because of the second equation
   \[ \sigma_{v}^2 = \sigma_{a}^2 + \sigma_{u}^2\]
   \item We will find $\sigma_{v}^2$ and $\sigma_{a}^2$, then deduce $\sigma_{u}^2$
  
 \end{itemize}
\item Because of our previous assumptions, 
\[\sigma_{v}^2 = \frac{1}{J}\sum_{j=1}^{J}E(v_{ij}^2)\]

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item This is true \emph{for each individual}
\item Replace $E(v_{ij}^2)$ with a sample average across $i$ using consistent estimates of $v_{ij}$
\end{itemize}

  \end{itemize}
  }
 
 
 
 
            \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item Because we have assumed $\mathbf{x_{ij}}$ and $a_{i}$ are \emph{uncorrelated}, we can obtain consistent estimates of  $v_{ij}$ from pooled OLS
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item Regress $y_{ij} =  \mathbf{x_{ij}}\boldsymbol{\beta} +v_{ij}$
  \item Keep the residuals from this regression, $\hat{v}_{ij}$
  \item Then for the estimate of $\sigma_{v}$
  \[ \hat{\sigma}_{v} = \frac{1}{NJ-K}\sum_{i=1}^{N}\sum_{j=1}^{J}\hat{v}_{ij}^2 \]
  \end{itemize}
 \item  Now, we obtain an estimate of $\sigma_{a}$ using a similar method
 \[\sigma_{a}^2 = \frac{1}{J(J-1)/2}\sum_{j=1}^{J-1}\sum_{s = j+1}^{J}E(v_{ij}v_{is})\]

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item This is true \emph{for each individual}
\item Replace $E(v_{ij}v_{is})$ with a sample average across $i$ using consistent estimates of $v_{ij}$
\end{itemize}
 \end{itemize}
  }
 
 
 
             \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

  \item The estimate of $\sigma_{a}^2 $ is
   \[\hat{\sigma}_{a}^2 = \frac{1}{NJ(J-1)/2 - K}\sum_{j=1}^{J-1}\sum_{s = j+1}^{J}\sum_{i=1}^{N}\hat{v}_{ij}\hat{v}_{is}\]
\item The idea is that there are $J(J-1)/2 $ cross-products of errors for each individual
\item Averaging these errors together for each person, then averaging across all people, we get a consistent estimate
\item Once we have $\hat{\sigma}_{a}^2$ and $\hat{\sigma}_{v}^2$, we obtain $\hat{\sigma}_{u}^2 = \hat{\sigma}_{v}^2-\hat{\sigma}_{a}^2$

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item Use these values in $\boldsymbol{\hat{\Omega}}$, and we have all that is required for the Random Effects Estimator
\end{itemize}


 \end{itemize}
  }
 
 
 
 
  
             \frame{
\frametitle{Panel Data Estimation Techniques}
 
  
\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 
\item With all of these assumptions, the variance estimate of the random effects estimator is

\[ \hat{var}( \boldsymbol{\hat{\beta}_{re}}) = \mathbf{(X'\boldsymbol{\hat{\Omega}}^{-1}X)^{-1} }\]

\item This procedure depends on the assumptions we have made about the random effects structure
\item We could also avoid those assumptions and use a robust variance estimator
\[\hat{var}(\boldsymbol{\hat{\beta}_{re}})= \mathbf{(X'\boldsymbol{\hat{\Omega}}^{-1}X)^{-1} }\left ( \sum_{i=1}^{n} \mathbf{X^{'}_{i} \hat{\Sigma}^{-1} \hat{u}_{i} \hat{u}_{i}^{'}\hat{\Sigma}^{-1}X_{i}}\right ) \mathbf{(X'\boldsymbol{\hat{\Omega}}^{-1}X)^{-1} }\]

\item But Random Effects is generally all about the structure of the errors

\begin{itemize}  \addtolength{\itemsep}{0.5\baselineskip} 

\item So if you are going to avoid making those assumptions, then you can use OLS
\end{itemize}

 \end{itemize}
  }
 

\end{document}