{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Prediction\"\n",
        "subtitle: \"EC295\"\n",
        "author: \"Justin Smith\"\n",
        "institute: \"Wilfrid Laurier University\"\n",
        "date: \"Fall 2022\"\n",
        "format: \n",
        "  revealjs:\n",
        "    theme: [default, hygge.scss]\n",
        "    smaller: true\n",
        "    slide-number: true    \n",
        "    width: 1280\n",
        "    height: 720\n",
        "    chalkboard:\n",
        "      theme: whiteboard\n",
        "      src: drawings.json\n",
        "editor: visual\n",
        "title-slide-attributes:\n",
        "  data-background-color: \"#43464B\"\n",
        "---"
      ],
      "id": "cb76fd13"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "## Introduction\n",
        "\n",
        "-   Our focus in this class has been on estimating the causal effect of $X$ on $Y$\n",
        "\n",
        "-   You can also use regressions to **predict** unknown outcomes\n",
        "\n",
        "-   Examples\n",
        "\n",
        "    -   The performance of a school that has not yet been built\n",
        "    \n",
        "    -   A stock price in the future\n",
        "    \n",
        "    -  Consumer spending under various levels of the interest rate \n",
        "    \n",
        "-  We can use our model with values of independent variables to estimate outcomes\n",
        "\n",
        "-  Predictions are estimates that are subject to error\n",
        "\n",
        "-  It is important to account for this error\n",
        "\n",
        "    -  Do this through **prediction intervals**\n",
        "\n",
        "## Introduction\n",
        "\n",
        "-  Like before, we want our predictions from OLS to be unbiased\n",
        "\n",
        "    -  Accurate on average\n",
        "\n",
        "-  Assumptions for this are different than before\n",
        "\n",
        "    -   Key difference: causal effects are not necessary for prediction\n",
        "\n",
        "-  Finally, we will examine how to compare different predictions\n",
        "\n",
        "    -  Based on the average error in prediction\n",
        "\n",
        "# Model and Estimation\n",
        "\n",
        "## Model\n",
        "\n",
        "-  We will start with a simple linear regression model\n",
        "\n",
        "$$Y = \\beta_{0} + \\beta_{1}X + u$$\n",
        "\n",
        "-  The slope and intercept are unknown parameters\n",
        "\n",
        "- Error term $u$ are other factors that affect $Y$\n",
        "\n",
        "- Ideally we could use $\\beta_{0} + \\beta_{1}X$ to predict $Y$\n",
        "\n",
        "- But these are not observed, so we need to estimate them\n",
        "\n",
        "## Estimation\n",
        "\n",
        "-  OLS estimates of the slope and intercept are\n",
        "\n",
        "$$\\hat{\\beta}_{0} = \\overline{Y} - \\hat{\\beta}_{1}\\overline{X}$$\n",
        "$$\\hat{\\beta}_{1} = \\frac{\\sum_{i=1}^{n}(X_{i} - \\overline{X})(Y_{i} - \\overline{Y})}{\\sum_{i=1}^{n}(X_{i} - \\overline{X})^2}$$\n",
        "\n",
        "-  Put estimates in place of unknown parameters\n",
        "\n",
        "$$Y = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X + \\hat{u}$$\n",
        "\n",
        "-  Generate predictions for $Y$ as a functon of $X$ with the sample regression function\n",
        "\n",
        "$$\\hat{Y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X$$\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "- Below we simulate 420 observations on test scores and student/teacher ratio\n",
        "\n",
        "\n",
        "```{stata, echo=TRUE, results=FALSE,  collectcode=TRUE}\n",
        "clear  \n",
        "set obs 420  \n",
        "set seed 12345  \n",
        "      \n",
        "gen str = rnormal(20,2)  \n",
        "gen u = rnormal(0,20)  \n",
        "      \n",
        "gen testscr = 700 -2 * str + u \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "- To predict test scores, first estimate the slope and intercept\n",
        "\n",
        "\n",
        "```{stata, echo=TRUE, collectcode=TRUE}\n",
        "regress testscr str\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "- Predicted values are computed using those estimates\n",
        "\n",
        "\n",
        "```{stata, echo=TRUE, collectcode=TRUE}\n",
        "gen pred_testscr = _b[_cons] + _b[str]*str\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "![](districtincome.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "# Nonlinear Functions of a Single Independent Variable\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   Recall graph on previous slide\n",
        "\n",
        "-   That line would fit better if curved\n",
        "\n",
        "    -   Effect of income on scores depends on income\n",
        "\n",
        "        -   Effect of income is large when income is low\n",
        "\n",
        "        -   Slope falls as income gets bigger\n",
        "\n",
        "        -   Called diminishing marginal returns\n",
        "\n",
        "-   The easiest way to allow curvature is a quadratic function\n",
        "\n",
        "-   A quadratic relationship between test scores and income is $$TestScore_{i} = \\beta_{0} + \\beta_{1}Income_{i} + \\beta_{2}Income_{i}^2 + u_{i}$$\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   The population regression function in this model is $$E[TestScore_{i}|Income_{i}] = \\beta_{0} + \\beta_{1}Income_{i} + \\beta_{2}Income_{i}^2$$\n",
        "\n",
        "-   This specification allows effect of income on test scores to depend on income\n",
        "\n",
        "-   To see this, compute total change in the population regression $$\\Delta E[TestScore_{i}|Income_{i}] = \\beta_{1}\\Delta Income_{i} + \\beta_{2}\\Delta Income_{i}^2$$\n",
        "\n",
        "-   Divide both sides by $\\Delta Income_{i}$ $$\\frac{ \\Delta E[TestScore_{i}|Income_{i}]}{\\Delta Income_{i}} = \\beta_{1}+ \\beta_{2}\\frac{\\Delta Income_{i}^2}{\\Delta Income_{i}}$$\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   When $\\Delta Income_{i}$ is small, we can approximate $\\frac{\\Delta Income_{i}^2}{\\Delta Income_{i}}$ $$\\frac{\\Delta Income_{i}^2}{\\Delta Income_{i}} \\approx 2Income_{i}$$\n",
        "\n",
        "-   Plugging into the main equation $$\\frac{E[TestScore_{i}|Income_{i}]}{\\Delta Income_{i}} = \\beta_{1}+ 2\\beta_{2}Income_{i}$$\n",
        "\n",
        "-   The effect of income on test scores has two components\n",
        "\n",
        "    -   $\\beta_{1}$, the effect of income on test scores when $Income_{i} = 0$\n",
        "\n",
        "    -   $2\\beta_{2}Income_{i}$, how the effect depends on income\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   The signs of $\\beta_{1}$ and $\\beta_{2}$ determine shape of function\n",
        "\n",
        "    -   If $\\beta_{1} >0$ and $\\beta_{2} <0$ it has inverted u shape\n",
        "\n",
        "        -   Effect of income on test scores is positive when income is low, and decreases as income gets larger\n",
        "\n",
        "        -   After certain point, effect becomes negative\n",
        "\n",
        "    -   If $\\beta_{1} <0$ and $\\beta_{2} >0$ it has u shape\n",
        "\n",
        "        -   Effect of income on test scores is negative when income is low, and increases as income gets larger\n",
        "\n",
        "        -   After certain point, effect becomes positive\n",
        "\n",
        "-   Estimate this equation by OLS the same way as before\n",
        "\n",
        "-   Estimated effect of income on test scores is $$\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta Income_{i}} = \\hat{\\beta}_{1}+ 2\\hat{\\beta}_{2}Income_{i}$$\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   Ex: estimated quadratic regression function $$\\hat{TestScore}_{i} = 607.3 + 3.85 Income - 0.0423 Income^2$$\n",
        "\n",
        "-   Estimated effect of income on test scores is $$\\frac{\\Delta\\hat{TestScore}_{i}}{\\Delta Income_{i}} = 3.85- 2(0.0423)Income_{i}$$\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   Note how effect depends on level of income\n",
        "\n",
        "    -   If income = 20,000 $$\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta Income_{i}} = 3.85- 2(0.0423)(20) = 2.158$$\n",
        "\n",
        "    -   If income = 40,000 $$\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta Income_{i}} = 3.85- 2(0.0423)(40) = 0.466$$\n",
        "\n",
        "    -   If income = 60,000 $$\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta Income_{i}} = 3.85- 2(0.0423)(60) = -1.226$$\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "-   Slope is high at low values of income, then falls as income grows larger\n",
        "\n",
        "    -   At very high income, effect is negative\n",
        "\n",
        "-   Function illustrated graphically on next slide\n",
        "\n",
        "-   Several notable features\n",
        "\n",
        "    -   Since $\\hat{\\beta}_{1} >0$ and $\\hat{\\beta}_{2} <0$ it has inverted u shape\n",
        "\n",
        "        -   Effect initially steep and positive\n",
        "\n",
        "        -   Flattens as income goes higher\n",
        "\n",
        "        -   Becomes negative after a certain point\n",
        "\n",
        "    -   Fits pattern of data much better\n",
        "\n",
        "        -   Especially at the ends\n",
        "\n",
        "        -   Likely $R^2$ would be higher in this regression\n",
        "\n",
        "## Quadratic Functions\n",
        "\n",
        "![](quad2.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Polynomial Functions\n",
        "\n",
        "-   We can allow for more flexibility in function with higher powers of $X$\n",
        "\n",
        "    -   Ex: cubic, quartic, etc\\...\n",
        "\n",
        "    -   Call these functions polynomials\n",
        "\n",
        "-   A polynomial relationship between $Y$ and $X$ of degree r is $$Y_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\beta_{2}X_{i}^2 + ... + \\beta_{r}X_{i}^r +u_{i}$$\n",
        "\n",
        "    -   The \"r\" determines highest power in function\n",
        "\n",
        "    -   When $r=2$ it is quadratic\n",
        "\n",
        "    -   When $r=3$ it is cubic\n",
        "\n",
        "-   Higher powers allow more bends in the function\n",
        "\n",
        "    -   Can help fit data better\n",
        "\n",
        "-   Effect of $X$ on $Y$ is more complicated with higher polynomials\n",
        "\n",
        "## Polynomial Functions\n",
        "\n",
        "-   Computing effect can be more difficult with higher powers\n",
        "\n",
        "-   Ex: estimated quadratic function $$\\hat{Y}_{i} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{i} + \\hat{\\beta}_{2}X_{i}^2$$ $$\\frac{\\Delta \\hat{Y}_{i}}{\\Delta X_{i}} = \\hat{\\beta}_{1}+ 2\\hat{\\beta}_{2}X_{i}$$\n",
        "\n",
        "-   Ex: estimated cubic function $$\\hat{Y}_{i} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{i} + \\hat{\\beta}_{2}X_{i}^2 + \\hat{\\beta}_{3}X_{i}^3$$ $$\\frac{\\Delta \\hat{Y}_{i}}{\\Delta X_{i}} = \\hat{\\beta}_{1}+ 2\\hat{\\beta}_{2}X_{i} + 3\\hat{\\beta}_{3}X_{i}^2$$\n",
        "\n",
        "-   and so on\n",
        "\n",
        "## Polynomial Functions\n",
        "\n",
        "![](poly.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Testing Null that the Regression is Linear\n",
        "\n",
        "-   We can test between polynomial and linear functions\n",
        "\n",
        "-   Procedure is to use an $F$-test as discussed last chapter\n",
        "\n",
        "-   First, estimate polynomial $$Y_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\beta_{2}X_{i}^2 + ... + \\beta_{r}X_{i}^r +u_{i}$$\n",
        "\n",
        "-   Then test between these hypotheses\n",
        "\n",
        "    -   $H_{0}: \\beta_{2} = 0, \\beta_{3} = 0, ..., \\beta_{r} = 0$\n",
        "\n",
        "    -   $H_{1}: \\text{ at least one of }\\beta_{2},\\beta_{3}, ..., \\beta_{r} \\text{ is not zero}$\n",
        "\n",
        "-   Accepting null means function is linear\n",
        "\n",
        "-   Rejecting means it is nonlinear in some way\n",
        "\n",
        "## Choosing the Degree of Polynomial\n",
        "\n",
        "-   Higher order polynomials increase flexibility of the regression\n",
        "\n",
        "-   But, if irrelevant can increase standard errors\n",
        "\n",
        "    -   Multicollinearity will reduce precision of other estimates\n",
        "\n",
        "-   Thus, it is important to properly specify degree of polynomial\n",
        "\n",
        "-   Textbook suggests following procedure\n",
        "\n",
        "    1.  Pick maximum value for $r$ and estimate regression\n",
        "\n",
        "    2.  Test null that $\\beta_{r}$ equals zero. If reject, keep in regression\n",
        "\n",
        "    3.  If accept null in 2, reestimate with polynomial of degree $r-1$\n",
        "\n",
        "    4.  Repeat 2-3 until you reject null hypothesis in 2\n",
        "\n",
        "-   This is sequentially pruning model to get right specification\n",
        "\n",
        "## Logarithms\n",
        "\n",
        "-   Common way to include nonlinearities is with logarithms\n",
        "\n",
        "-   What is a logarithm?\n",
        "\n",
        "    -   Logarithm of $x$ to base $b$ is the $y$ that solves $b^{y} = x$ $$log_{b}(x) = y$$\n",
        "\n",
        "    -   Ex: If $x$ is 1000, and the base $b$ is 10, the logarithm of $x$ is the exponent that turns 10 into 1000 $$log_{10}(1000) = 3$$\n",
        "\n",
        "    -   Increasing $log_{10}(x)$ by one unit is like multiplying $x$ by 10\n",
        "\n",
        "    -   10 is a common base, but it can be any number\n",
        "\n",
        "    -   Ex: Richter scale (for earthquakes) is a base-10 log scale\n",
        "\n",
        "## Logarithms\n",
        "\n",
        "|               |     |     |     |      |       |        |\n",
        "|:--------------|:---:|:---:|:---:|:----:|:-----:|:------:|\n",
        "| x             |  1  | 10  | 100 | 1000 | 10000 | 100000 |\n",
        "| $log_{10}(x)$ |  0  |  1  |  2  |  3   |   4   |   5    |\n",
        "\n",
        ": Base 10 Logarithm\n",
        "\n",
        "-   Economists often use the *natural logarithm*\n",
        "\n",
        "    -   Logarithm with b equal to $e = 2.71828$\n",
        "\n",
        "    -   Often written as $ln(x)$\n",
        "\n",
        "    -   Increasing $ln(x)$ by one unit is like multiplying by 2.71828\n",
        "\n",
        "-   Natural logarithms have one key useful property\n",
        "\n",
        "    -   Small changes in $ln(x)$ approximate a percentage change $$100 \\times (ln(x +\\Delta x) - ln(x)) =100 \\times \\Delta ln(x)  \\approx 100\\times \\left ( \\frac{\\Delta x}{x} \\right )$$\n",
        "\n",
        "## Logarithms\n",
        "\n",
        "-   Ex: let $x = 100$ and $\\Delta x = 1$\n",
        "\n",
        "    -   Actual percentage change is: $100\\times \\left (\\frac{101 - 100}{100} \\right ) = 1$\n",
        "\n",
        "    -   Log approximation is $100 \\times (ln(101) - ln(100)) = 100 \\times (4.615 -4.605) =1$\n",
        "\n",
        "-   Useful for expressing $X$, $Y$, or both in percentage terms\n",
        "\n",
        "    -   If $X$ changes by 1 unit, what is percentage effect on $Y$?\n",
        "\n",
        "    -   If $X$ changes by 1% , what is effect on $Y$?\n",
        "\n",
        "    -   If $X$ changes by 1%, what is percentage effect on $Y$?\n",
        "\n",
        "-   The inverse of a natural logarithm is the exponential function $$x = e^{ln(x)}$$\n",
        "\n",
        "    -   This will become useful in some situations\n",
        "\n",
        "## Log-Linear Model\n",
        "\n",
        "-   A **log-linear** model is when $Y$ is in logs, but $X$ is not $$ln(Y_{i}) = \\beta_{0}+\\beta_{1}X_{i} + u_{i}$$\n",
        "\n",
        "-   Often used when measuring the return to education\n",
        "\n",
        "-   A common population regression model in this context is $$ln(wage) = \\beta_{0} + \\beta_{1}educ + u$$\n",
        "\n",
        "-   The interpretation of $\\beta_{1}$ is $$\\beta_{1} = \\frac{\\Delta ln(wage)}{\\Delta educ}$$\n",
        "\n",
        "-   Remember that $100\\times \\Delta ln(wage)$ is roughly equal to % change in wage\n",
        "\n",
        "## Log-Linear Model\n",
        "\n",
        "-   So if we multiply $\\beta_{1}$ by 100 then $$100\\times \\beta_{1} \\approx \\frac{\\% \\Delta wage}{\\Delta educ}$$\n",
        "\n",
        "    -   $100\\times \\beta_{1}$ measures the % change in wage due to a 1-year increase in education\n",
        "\n",
        "-   Appropriate if each year of education has equal *proportional* change in wage\n",
        "\n",
        "    -   Increasing education raises wage by same percentage\n",
        "\n",
        "-   In the general model $$100\\times \\beta_{1} \\approx \\frac{\\% \\Delta Y_{i}}{\\Delta X_{i}}$$\n",
        "\n",
        "## Linear-Log Model\n",
        "\n",
        "-   A **linear-log** model is when $X$ is in logs, but $Y$ is not $$Y_{i} = \\beta_{0}+\\beta_{1}ln(X_{i}) + u_{i}$$\n",
        "\n",
        "-   One application is the effect of GDP on life expectancy $$expectancy= \\beta_{0} + \\beta_{1}ln(GDP) + u$$\n",
        "\n",
        "    -   Appropriate if proportional changes in GDP have same effect on expectancy\n",
        "\n",
        "    -   Larger increases in GDP are needed to get same effect on expectancy as countries get richer\n",
        "\n",
        "    $$\\beta_{1} = \\frac{\\Delta expectancy}{\\Delta ln(GDP)}$$\n",
        "\n",
        "## Linear-Log Model\n",
        "\n",
        "-   If we divide $\\beta_{1}$ by 100 $$\\frac{\\beta_{1}}{100} = \\frac{\\Delta expectancy}{100 \\times \\Delta ln(GDP)} = \\frac{\\Delta expectancy}{\\% \\Delta GDP}$$\n",
        "\n",
        "-   $\\frac{\\beta_{1}}{100}$ measures effect of 1% change in GDP on expectancy\n",
        "\n",
        "-   In the general model $$\\frac{\\beta_{1}}{100} = \\frac{\\Delta Y_{i}}{\\% \\Delta X_{i}}$$\n",
        "\n",
        "-   It is relatively rare to see this model in practice\n",
        "\n",
        "## Log-Log Model\n",
        "\n",
        "-   A **log-log** model is when both $Y$ and $X$ are in logs $$ln(Y_{i}) = \\beta_{0}+\\beta_{1}ln(X_{i}) + u_{i}$$\n",
        "\n",
        "-   This is used to estimate the *elasticity* between $X$ and $Y$\n",
        "\n",
        "-   Suppose you want to know price elasticity of demand for ticket sales $$ln(sales)= \\beta_{0} + \\beta_{1}ln(price) + u$$\n",
        "\n",
        "-   In this case $$\\beta_{1} = \\frac{\\Delta ln(sales)}{\\Delta ln(price)}$$\n",
        "\n",
        "## Log-Log Model\n",
        "\n",
        "-   If we multiply and divide $\\beta_{1}$ by 100 $$\\beta_{1} = \\frac{100\\times \\Delta ln(sales)}{100 \\times \\Delta ln(price)} =  \\frac{\\% \\Delta sales}{\\% \\Delta price}$$\n",
        "\n",
        "-   $\\beta_{1}$ measures percent effect on ticket sales from a 1% increase in price\n",
        "\n",
        "    -   This is the price elasticity of demand for ticket sales\n",
        "\n",
        "-   In the general model $$\\beta_{1} =  \\frac{\\% \\Delta Y_{i}}{\\% \\Delta X_{i}}$$\n",
        "\n",
        "-   Note that you do not need to alter $\\beta_{1}$ before interpreting\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](matrix.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](loglinear.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](linearlog.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](linearlog2.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](loglog.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Visualizing Nonlinear Models\n",
        "\n",
        "![](comparelog.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   We continue above with the relationship between test scores and district income\n",
        "\n",
        "-   Below we estimate various nonlinear functions of income\n",
        "\n",
        "    -   Linear: $TestScore_{i}= \\beta_{0} + \\beta_{1}Income_{i} + u_{i}$\n",
        "\n",
        "    -   Quadratic: $TestScore_{i}= \\beta_{0} + \\beta_{1}Income_{i} + \\beta_{2}Income_{i}^2+ u_{i}$\n",
        "\n",
        "    -   Log Linear: $ln(TestScore_{i})= \\beta_{0} + \\beta_{1}Income_{i} + u_{i}$\n",
        "\n",
        "    -   Linear Log: $TestScore_{i}= \\beta_{0} + \\beta_{1}ln(Income_{i}) + u_{i}$\n",
        "\n",
        "    -   Log Log: $ln(TestScore_{i})= \\beta_{0} + \\beta_{1}ln(Income_{i}) + u_{i}$\n",
        "\n",
        "-   We will interpret coefficients in each\n",
        "\n",
        "## Example with Stata {.r-fit-text background-color=\"#d9edc2\"}\n",
        "\n",
        "-   First, create necessary variables\n",
        "\n",
        "-   Then estimate regressions\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    **Create variables we need for the regression;\n",
        "\n",
        "        gen avginc2 = avginc^2;\n",
        "\n",
        "        gen lntestscr = ln(testscr);\n",
        "        gen lnavginc = ln(avginc);\n",
        "\n",
        "    **Estimate regressions;\n",
        "        \n",
        "        regress testscr avginc;\n",
        "            estimates store linear;\n",
        "            \n",
        "        regress testscr avginc avginc2;\n",
        "            estimates store quadratic;\n",
        "            \n",
        "        regress lntestscr avginc;\n",
        "            estimates store loglinear;\n",
        "            \n",
        "        regress testscr lnavginc;\n",
        "            estimates store linearlog;\n",
        "            \n",
        "        regress lntestscr lnavginc;\n",
        "            estimates store loglog;\n",
        "\n",
        "## Example with Stata {.r-fit-text background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Export results in easy to read table\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    .  estout linear quadratic linearlog loglinear loglog, cells(b(star fmt(3)) \n",
        "        se(par fmt(3))) starlevels(* 0.05 ** 0.01 ) stats(r2 r2_a rmse N,fmt(3 3 3 0 ));\n",
        "\n",
        "    ---------------------------------------------------------------------------------------\n",
        "                       linear      quadratic      linearlog      loglinear         loglog  \n",
        "                         b/se           b/se           b/se           b/se           b/se  \n",
        "    ---------------------------------------------------------------------------------------\n",
        "    avginc              1.879**        3.851**                       0.003**               \n",
        "                      (0.091)        (0.304)                       (0.000)                 \n",
        "    avginc2                           -0.042**                                             \n",
        "                                     (0.006)                                               \n",
        "    lnavginc                                         36.420**                       0.055**\n",
        "                                                    (1.571)                       (0.002)  \n",
        "    _cons             625.384**      607.302**      557.832**        6.439**        6.336**\n",
        "                      (1.532)        (3.046)        (4.200)        (0.002)        (0.006)  \n",
        "    ---------------------------------------------------------------------------------------\n",
        "    r2                  0.508          0.556          0.563          0.498          0.558  \n",
        "    r2_a                0.506          0.554          0.561          0.497          0.557  \n",
        "    rmse               13.387         12.724         12.618          0.021          0.019  \n",
        "    N                     420            420            420            420            420  \n",
        "    ---------------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Linear model\n",
        "\n",
        "    -   Income increases by \\$1000, test scores increase by 1.879 points\n",
        "\n",
        "-   Quadratic model\n",
        "\n",
        "    -   $\\frac{\\Delta TestScore}{\\Delta Income} = 3.851-2(0.042)Income$\n",
        "\n",
        "    -   When Income = 0, if income increases by \\$1000, test scores increase by 3.851 points\n",
        "\n",
        "    -   $\\frac{\\Delta TestScore}{\\Delta Income}$ is smaller by 2(0.042) with each \\$1000 in income\n",
        "\n",
        "    -   When Income = 50000, if income increases by \\$1000, test scores fall by 3.851-2(0.042)50 = -0.349 points\n",
        "\n",
        "-   Linear Log model\n",
        "\n",
        "    -   $\\frac{\\beta_{1}}{100} = \\frac{\\Delta TestScore}{\\% \\Delta Income}$\n",
        "\n",
        "    -   $\\frac{\\beta_{1}}{100} = \\frac{36.420}{100} = 0.364$\n",
        "\n",
        "    -   Income increases by 1%, test scores rise by 0.364 points\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Log Linear model\n",
        "\n",
        "    -   $100\\beta_{1} = \\frac{\\% \\Delta TestScore}{\\Delta Income}$\n",
        "\n",
        "    -   $100\\beta_{1} = 100(0.003) = 0.3$\n",
        "\n",
        "    -   Income increases by \\$1000, test scores rise by 0.3%\n",
        "\n",
        "-   Log Log model\n",
        "\n",
        "    -   $\\beta_{1} = \\frac{\\% \\Delta TestScore}{\\% \\Delta Income}$\n",
        "\n",
        "    -   $\\beta_{1} = 0.055$\n",
        "\n",
        "    -   Income increases by 1%, test scores rise by 0.055%\n",
        "\n",
        "    -   This is the elasticity of test scores with respect to income\n",
        "\n",
        "# Interactions Between Variables\n",
        "\n",
        "## Introduction\n",
        "\n",
        "-   Quadratics allowed effect of $X$ on $Y$ to depend on $X$\n",
        "\n",
        "    -   Ex: Effect of experience on wages depends on current experience\n",
        "\n",
        "-   We can also allow effect of $X$ on $Y$ to depend on third variable $Z$\n",
        "\n",
        "    -   Ex: Effect of experience on wages may depend on education\n",
        "\n",
        "    -   Ex: Effect of experience on wages may depend on gender\n",
        "\n",
        "-   We allow for this dependence with interaction terms\n",
        "\n",
        "    -   The product of two independent variables\n",
        "\n",
        "-   In this section we study variable interactions\n",
        "\n",
        "    -   Between dummies and continuous variables\n",
        "\n",
        "    -   Also between continuous variables\n",
        "\n",
        "## Model with Multiple Dummy Variables\n",
        "\n",
        "-   First, we examine a model with two dummy variables but no interaction\n",
        "\n",
        "-   Suppose we are interested in the effect of gender and marriage on wages $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}marr_{i} + u_{i}$$\n",
        "\n",
        "-   In this model,\n",
        "\n",
        "    -   $fem_{i} = 1$ for women, and zero otherwise\n",
        "\n",
        "    -   $marr_{i}=1$ if married, and zero otherwise\n",
        "\n",
        "-   How do we interpret the parameters of this model?\n",
        "\n",
        "## Model with Multiple Dummy Variables\n",
        "\n",
        "-   As before, look at population regression function\n",
        "\n",
        "    -   When $fem_{i} =1$ and $marr_{i} = 1$ $$E[wage_{i}|fem_{i}=1,marr_{i}=1] =  \\beta_{0} + \\beta_{1}+ \\beta_{2}$$\n",
        "\n",
        "    -   When $fem_{i} =1$ and $marr_{i} = 0$ $$E[wage_{i}|fem_{i}=1,marr_{i}=0] =  \\beta_{0} + \\beta_{1}$$\n",
        "\n",
        "    -   When $fem_{i} =0$ and $marr_{i} = 1$ $$E[wage_{i}|fem_{i}=0,marr_{i}=1] =  \\beta_{0} + \\beta_{2}$$\n",
        "\n",
        "    -   When $fem_{i} =0$ and $marr_{i} = 0$ $$E[wage_{i}|fem_{i}=0,marr_{i}=0] =  \\beta_{0}$$\n",
        "\n",
        "## Model with Multiple Dummy Variables\n",
        "\n",
        "-   $\\beta_{0}$ is average wage when male, unmarried $$E[wage_{i}|fem_{i}=0,marr_{i}=0] =  \\beta_{0}$$\n",
        "\n",
        "-   $\\beta_{1}$ is difference between unmarried woman and unmarried man $$E[wage_{i}|fem_{i}=1,marr_{i}=0]  - E[wage_{i}|fem_{i}=0,marr_{i}=0]$$ $$= \\beta_{0} + \\beta_{1} -  \\beta_{0}$$ $$= \\beta_{1}$$\n",
        "\n",
        "-   $\\beta_{1}$ [also]{.underline} difference between married woman and married man $$E[wage_{i}|fem_{i}=1,marr_{i}=1]  - E[wage_{i}|fem_{i}=0,marr_{i}=1]$$ $$=  \\beta_{0} + \\beta_{1}+ \\beta_{2} - (\\beta_{0} + \\beta_{2})$$ $$= \\beta_{1}$$\n",
        "\n",
        "## Model with Multiple Dummy Variables\n",
        "\n",
        "-   Model imposes that female-male difference does not depend on marriage\n",
        "\n",
        "    -   It is equal to $\\beta_{1}$ regardless of marital status\n",
        "\n",
        "-   $\\beta_{2}$ is married-unmarried difference\n",
        "\n",
        "    -   Like before, difference does not depend on gender\n",
        "\n",
        "    $$E[wage_{i}|fem_{i}=0,marr_{i}=1] - E[wage_{i}|fem_{i}=0,marr_{i}=0]$$ $$=  \\beta_{0} + \\beta_{2} -  \\beta_{0}$$ $$=  \\beta_{2}$$ $$E[wage_{i}|fem_{i}=1,marr_{i}=1] - E[wage_{i}|fem_{i}=1,marr_{i}=0]$$ $$=  \\beta_{0} + \\beta_{1}+ \\beta_{2} - (\\beta_{0} + \\beta_{1})$$ $$=  \\beta_{2}$$\n",
        "\n",
        "## Model with Multiple Dummy Variables\n",
        "\n",
        "-   In total model has four intercepts\n",
        "\n",
        "    -   married women: $\\beta_{0} + \\beta_{1}+ \\beta_{2}$\n",
        "\n",
        "    -   unmarried women: $\\beta_{0} + \\beta_{1}$\n",
        "\n",
        "    -   married men: $\\beta_{0} + \\beta_{2}$\n",
        "\n",
        "    -   unmarried men: $\\beta_{0}$\n",
        "\n",
        "-   Key limitation is female/male differences do not depend on marriage\n",
        "\n",
        "-   Also, married/unmarried differences do not depend on gender\n",
        "\n",
        "-   Both of these restrictions are specific to this model\n",
        "\n",
        "    -   We can relax them with interaction terms\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   As an example, we study the determinants of wages\n",
        "\n",
        "-   We are using the 2011 Survey of Labour and Income Dynamics (SLID)\n",
        "\n",
        "    -   Canadian survey on workers in Canada\n",
        "\n",
        "    -   Information on earnings, work hours, demographics, jobs\n",
        "\n",
        "    -   Follows people across time\n",
        "\n",
        "    -   We use the 2011 survey only\n",
        "\n",
        "-   There are about 47,000 observations total\n",
        "\n",
        "    -   We use a subset of about 16,000\n",
        "\n",
        "-   Drop a few values due to missing information on education\n",
        "\n",
        "-   The datafile and dofile are posted to mylearningspace\n",
        "\n",
        "    -   Datafile: **slid.dta**\n",
        "\n",
        "    -   Dofile: **EC295 nonlinear regression part 2.do**\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Suppose we regress wages on a female and married dummy $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i}+ \\beta_{2}marr_{i} + u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(2, 15814)       =     466.21\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.0590\n",
        "                                                    Root MSE          =     13.432\n",
        "\n",
        "    ------------------------------------------------------------------------------\n",
        "                 |               Robust\n",
        "        cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    -------------+----------------------------------------------------------------\n",
        "          female |  -4.245531   .2110128   -20.12   0.000     -4.65914   -3.831921\n",
        "         married |   5.093432   .2080484    24.48   0.000     4.685633    5.501231\n",
        "           _cons |   25.74684   .1798452   143.16   0.000     25.39432    26.09935\n",
        "    ------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Based on these estimates\n",
        "\n",
        "    -   Women earn \\$4.25 less than men, on average\n",
        "\n",
        "    -   Married people earn \\$5.09 more than unmarried, on average\n",
        "\n",
        "    -   Different intercepts are\n",
        "\n",
        "        -   Unmarried men: $\\hat{\\beta}_{0} = 25.75$\n",
        "\n",
        "        -   Unmarried women: $\\hat{\\beta}_{0} + \\hat{\\beta}_{1} = 25.75-4.25 = 21.50$\n",
        "\n",
        "        -   Married men: $\\hat{\\beta}_{0} + \\hat{\\beta}_{2} = 25.75+5.09 = 30.84$\n",
        "\n",
        "        -   Married women: $\\hat{\\beta}_{0}+ \\hat{\\beta}_{1} +\\hat{\\beta}_{2}= 25.75- 4.25+5.09 = 26.59$\n",
        "\n",
        "    -   Notice female/male difference is $-4.25$ regardless of marital status\n",
        "\n",
        "    -   Also married/unmarried difference is $5.09$ regardless of gender\n",
        "\n",
        "## Interactions Among Dummy Variables\n",
        "\n",
        "-   Recall the model $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} +\\beta_{2}marr_{i} + u_{i}$$\n",
        "\n",
        "    -   The female-male difference is measured by $\\beta_{1}$\n",
        "\n",
        "    -   The married-unmarried difference is measured by $\\beta_{2}$\n",
        "\n",
        "-   A key limitation of this model was that\n",
        "\n",
        "    -   The female-male difference did not depend on marital status\n",
        "\n",
        "    -   The married-unmarried difference did not depend on gender\n",
        "\n",
        "-   Interacting the two variables changes that interpretation\n",
        "\n",
        "## Interactions Among Dummy Variables\n",
        "\n",
        "-   Suppose we add an interaction between $fem_{i}$ and $marr_{i}$ $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} +\\beta_{2}marr_{i} +\\beta_{3}(fem_{i}\\times marr_{i}) + u_{i}$$\n",
        "\n",
        "-   Now suppose we measure the female-male difference\n",
        "\n",
        "    $$E[wage_{i}|marr_{i} , fem_{i} = 1]  - E[wage_{i}|marr_{i} , fem_{i} =0]$$ $$= ( \\beta_{0} + \\beta_{1} + \\beta_{2}marr_{i} +\\beta_{3}marr_{i} )$$ $$-  (\\beta_{0}  + \\beta_{2}marr_{i} )$$ $$= \\beta_{1} + \\beta_{3}marr_{i}$$\n",
        "\n",
        "-   Now, the female-male gap *depends* on the marital status\n",
        "\n",
        "    -   The gap is different depending on value of $marr_{i}$\n",
        "\n",
        "## Interactions Among Dummy Variables\n",
        "\n",
        "-   To see this, compute the female-male gap for unmarried and married\n",
        "\n",
        "    -   For unmarried people $$E[wage_{i}|fem_{i}=1,marr_{i}=0]  - E[wage_{i}|fem_{i}=0,marr_{i}=0]$$ $$= \\beta_{0} + \\beta_{1} -  \\beta_{0}$$ $$= \\beta_{1}$$\n",
        "\n",
        "    -   For married people $$E[wage_{i}|fem_{i}=1,marr_{i}=1]  - E[wage_{i}|fem_{i}=0,marr_{i}=1]$$ $$=  \\beta_{0} + \\beta_{1}+ \\beta_{2} + \\beta_{3} - (\\beta_{0} + \\beta_{2})$$ $$= \\beta_{1} + \\beta_{3}$$\n",
        "\n",
        "## Interactions Among Dummy Variables {.r-fit-text}\n",
        "\n",
        "-   Likewise, married unmarried gap depends on gender $$E[wage_{i}|marr_{i} = 1 , fem_{i} ]  - E[wage_{i}|marr_{i}=0 , fem_{i}]$$ $$=( \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2} +\\beta_{3}fem_{i} )  -  (\\beta_{0}  + \\beta_{1}fem_{i}  )$$\n",
        "\n",
        "    $$=  \\beta_{2}+\\beta_{3}fem_{i}$$\n",
        "\n",
        "    -   marriage gap for men is $$E[wage_{i}|marr_{i} = 1 , fem_{i} = 0 ]  - E[wage_{i}|marr_{i}=0 , fem_{i} = 0]$$ $$=  \\beta_{2}$$\n",
        "\n",
        "    -   Marriage gap for women is $$E[wage_{i}|marr_{i} = 1 , fem_{i} = 1 ]  - E[wage_{i}|marr_{i}=0 , fem_{i} = 1]$$ $$=  \\beta_{2} + \\beta_{3}$$\n",
        "\n",
        "## Interactions Among Dummy Variables\n",
        "\n",
        "-   To summarize, interacting dummies allows for\n",
        "\n",
        "    -   Different intercepts for all groups\n",
        "\n",
        "    -   Differences in intercepts depend on group status\n",
        "\n",
        "-   The different intercepts of this model are\n",
        "\n",
        "    -   Unmarried men: $\\beta_{0}$\n",
        "\n",
        "    -   Unmarried women: $\\beta_{0} + \\beta_{1}$\n",
        "\n",
        "    -   Married men: $\\beta_{0} + \\beta_{2}$\n",
        "\n",
        "    -   Married women: $\\beta_{0} + \\beta_{1} + \\beta_{2}+ \\beta_{3}$\n",
        "\n",
        "## Interactions Among Dummy Variables\n",
        "\n",
        "-   The interpretations for each are as follows\n",
        "\n",
        "    -   $\\beta_{1}$: difference between unmarried women and unmarried men\n",
        "\n",
        "    -   $\\beta_{2}$: difference between married men and unmarried men\n",
        "\n",
        "    -   $\\beta_{3}$: more complicated\n",
        "\n",
        "        -   Gender gap for married people minus gender gap for unmarried people\n",
        "\n",
        "        -   Marriage gap for women minus marriage gap for men\n",
        "\n",
        "        -   Measures how gender gap depends on marriage, and how marriage gap depends on gender\n",
        "\n",
        "        -   It is sometimes called the **difference in differences**\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Suppose we interact female and married $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} +\\beta_{2}marr_{i} +\\beta_{3}(fem_{i}\\times marr_{i}) + u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    .  gen female_married = female*married;\n",
        "    .  regress cmphrw28 female married female_married, robust  ;\n",
        "\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(3, 15813)       =     313.66\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.0645\n",
        "                                                    Root MSE          =     13.393\n",
        "\n",
        "    --------------------------------------------------------------------------------\n",
        "                   |               Robust\n",
        "          cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    ---------------+----------------------------------------------------------------\n",
        "            female |  -1.911665   .2772196    -6.90   0.000    -2.455047   -1.368283\n",
        "           married |   7.098604   .3130463    22.68   0.000     6.484998    7.712211\n",
        "    female_married |  -4.143398    .412491   -10.04   0.000    -4.951927   -3.334868\n",
        "             _cons |   24.57583   .2062195   119.17   0.000     24.17162    24.98005\n",
        "    --------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   In this model,\n",
        "\n",
        "    -   female-male wage gap is $\\beta_{1}+ \\beta_{3}marr_{i}$\n",
        "\n",
        "    -   married-unmarried wage gap is $\\beta_{2}+ \\beta_{3}fem_{i}$\n",
        "\n",
        "-   Based on these results\n",
        "\n",
        "    -   $\\beta_{1} = -1.92$ wage gap between female and male unmarried people\n",
        "\n",
        "    -   $\\beta_{2} = 7.09$: wage gap between married and unmarried men\n",
        "\n",
        "    -   $\\beta_{3} = -4.14$:\n",
        "\n",
        "        -   *difference* in gender gap between married and unmarried\n",
        "\n",
        "        -   It is also *difference* in marriage gap between women and men\n",
        "\n",
        "-   Note how $\\beta_{3}$ measures change in gender gap for married, and also change in marriage gap for women\n",
        "\n",
        "## Models with Dummy and Continuous Variables\n",
        "\n",
        "-   Suppose we are interested in estimating\n",
        "\n",
        "    $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i} + u_{i}$$\n",
        "\n",
        "    -   $wage_{i}$ is an individual's wage in dollars\n",
        "\n",
        "    -   $fem_{i}$ is a dummy variable equal to 1 if female, 0 if male\n",
        "\n",
        "    -   $educ_{i}$ is total years of schooling\n",
        "\n",
        "-   The model contains one dummy, one continuous independent variable\n",
        "\n",
        "-   To understand interpretation of $\\beta_{1}$, take expected value $$E[wage_{i}|fem_{i},educ_{i}] = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i}$$\n",
        "\n",
        "## Models with Dummy and Continuous Variables\n",
        "\n",
        "-   When $fem_{i}$ = 1 $$E[wage_{i}|fem_{i} = 1,educ_{i}] = \\beta_{0} + \\beta_{1}+ \\beta_{2}educ_{i}$$\n",
        "\n",
        "-   When $fem_{i}$= 0 $$E[wage_{i}|fem_{i} = 0,educ_{i}] = \\beta_{0}  + \\beta_{2}educ_{i}$$\n",
        "\n",
        "-   Taking the difference $$E[wage_{i}|fem_{i} = 1,educ_{i}]  - E[wage_{i}|fem_{i} = 0,educ_{i}] =$$ $$(\\beta_{0} + \\beta_{1}+ \\beta_{2}educ_{i}) -  (\\beta_{0}  + \\beta_{2}educ_{i} ) =\\beta_{1}$$\n",
        "\n",
        "-   $\\beta_{1}$ is difference in average wage between women and men $$\\beta_{1} = E[wage_{i}|fem_{i} = 1,educ_{i}]  - E[wage_{i}|fem_{i} = 0,educ_{i}]$$\n",
        "\n",
        "## Models with Dummy and Continuous Variables\n",
        "\n",
        "-   Notice that in expectation, we are holding education constant\n",
        "\n",
        "    -   Level of education is same in both expectations\n",
        "\n",
        "    -   $\\beta_{1}$ measures gender difference *at each level of education*\n",
        "\n",
        "-   Can view $\\beta_{1}$ as an **intercept shift**\n",
        "\n",
        "    -   Intercept $\\beta_{0}$ is $wage$ when independent variables are zero\n",
        "\n",
        "        $$E[wage_{i}|fem_{i} = 0,educ_{i}=0] = \\beta_{0}$$\n",
        "\n",
        "    -   In this model, it is average wages of male with zero education\n",
        "\n",
        "    -   Average wage of woman with no education is $$E[wage_{i}|fem_{i} = 1,educ_{i}=0] = \\beta_{0} + \\beta_{1}$$\n",
        "\n",
        "    -   So, $\\beta_{1}$ measures how average wage with no education changes between women and men\n",
        "\n",
        "        -   This allows different intercepts between men and women\n",
        "\n",
        "## Models with Dummy and Continuous Variables\n",
        "\n",
        "![](interceptshift.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Interactions Between Continuous and Dummy Variables\n",
        "\n",
        "-   We just saw how to allow for intercepts between groups\n",
        "\n",
        "    -   Adding dummy variable for the group\n",
        "\n",
        "-   We can also allow for the *slopes* to depend on groups\n",
        "\n",
        "-   Suppose we interact *female* with *educ* $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i} +\\beta_{3}(fem_{i} \\times educ_{i})+ u_{i}$$\n",
        "\n",
        "-   The effect of $educ_{i}$ on $E[wage_{i}|fem_{i},educ_{i}]$ is measured by\n",
        "\n",
        "    $$\\frac{\\Delta E[wage_{i}|fem_{i},educ_{i}] }{\\Delta educ_{i}} =  \\beta_{2} + \\beta_{3}fem_{i}$$\n",
        "\n",
        "## Interactions Between Continuous and Dummy Variables\n",
        "\n",
        "-   In this setup\n",
        "\n",
        "    -   $\\beta_{2}$ measures effect of $educ_{i}$ on $wage_{i}$ when $fem_{i} = 0$\n",
        "\n",
        "        -   Slope between educ and wage for men\n",
        "\n",
        "    -   $\\beta_{2}+\\beta_{3}$ measures effect of $educ_{i}$ on $wage_{i}$ when $fem_{i} = 1$\n",
        "\n",
        "        -   Slope between educ and wage for women\n",
        "\n",
        "    -   $\\beta_{3}$ is *difference* in slope between women and men\n",
        "\n",
        "-   Interacting a dummy with continuous variable allows for different slopes between groups\n",
        "\n",
        "-   With a dummy variable on its own, and interacted with continuous variable, we allow different intercept *and* slope\n",
        "\n",
        "    -   Dummy allows for different intercept\n",
        "\n",
        "    -   Interaction with dummy allows for different slope\n",
        "\n",
        "## Interactions Between Continuous and Dummy Variables\n",
        "\n",
        "![](slopeinterceptshift.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Interactions Between Continuous and Dummy Variables\n",
        "\n",
        "-   In rare cases, you can also estimate a model with the same intercept, but different slopes $$wage_{i} = \\beta_{0}  + \\beta_{2}educ_{i} +\\beta_{3}(fem_{i} \\times educ_{i})+ u_{i}$$\n",
        "\n",
        "    -   Excludes the dummy variable on its own\n",
        "\n",
        "    -   This eliminates the intercept shift\n",
        "\n",
        "-   In this setup\n",
        "\n",
        "    -   $\\beta_{0}$ is the intercept for men and women\n",
        "\n",
        "    -   $\\beta_{2}$ measures slope on $educ_{i}$ for men\n",
        "\n",
        "    -   $\\beta_{2}+\\beta_{3}$ measures slope on $educ_{i}$ for women\n",
        "\n",
        "    -   $\\beta_{3}$ is *difference* in slope between women and men\n",
        "\n",
        "## Interactions Between Continuous and Dummy Variables\n",
        "\n",
        "![](slopeshift.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   A model with intercept shift but same slopes would be $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i} + u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    .  regress cmphrw28 female yrschl18, robust  ;\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(2, 15814)       =    1342.07\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.1918\n",
        "                                                    Root MSE          =     12.448\n",
        "\n",
        "    ------------------------------------------------------------------------------\n",
        "                 |               Robust\n",
        "        cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    -------------+----------------------------------------------------------------\n",
        "          female |  -5.310934   .1987372   -26.72   0.000    -5.700481   -4.921386\n",
        "        yrschl18 |   2.078491   .0424539    48.96   0.000     1.995277    2.161706\n",
        "           _cons |   .3170835   .5522942     0.57   0.566    -.7654761    1.399643\n",
        "    ------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   A model with intercept shift and different slopes is $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i} +\\beta_{3}(fem_{i} \\times educ_{i})+ u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    . gen female_yrschl18 = female*yrschl18;\n",
        "    .  regress cmphrw28 female yrschl18 female_yrschl18, robust  ;\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(3, 15813)       =    1030.03\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.1918\n",
        "                                                    Root MSE          =     12.449\n",
        "\n",
        "    ---------------------------------------------------------------------------------\n",
        "                    |               Robust\n",
        "           cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    ----------------+----------------------------------------------------------------\n",
        "             female |   -5.43323   1.093145    -4.97   0.000     -7.57592   -3.290541\n",
        "           yrschl18 |   2.074593   .0628544    33.01   0.000     1.951391    2.197794\n",
        "    female_yrschl18 |   .0088005   .0830051     0.11   0.916     -.153899    .1715001\n",
        "              _cons |   .3703632    .813796     0.46   0.649     -1.22477    1.965496\n",
        "    ---------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   A model with same intercepts but different slopes is $$wage_{i} = \\beta_{0} + \\beta_{1}fem_{i} + \\beta_{2}educ_{i} +\\beta_{3}(fem_{i} \\times educ_{i})+ u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    . regress cmphrw28 yrschl18 female_yrschl18, robust  ;\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(2, 15814)       =    1266.52\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.1904\n",
        "                                                    Root MSE          =     12.459\n",
        "\n",
        "    ---------------------------------------------------------------------------------\n",
        "                    |               Robust\n",
        "           cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    ----------------+----------------------------------------------------------------\n",
        "           yrschl18 |   2.238699   .0447701    50.00   0.000     2.150944    2.326454\n",
        "    female_yrschl18 |  -.3678847   .0152029   -24.20   0.000    -.3976841   -.3380852\n",
        "              _cons |  -1.966818   .5616236    -3.50   0.000    -3.067664   -.8659719\n",
        "    ---------------------------------------------------------------------------------\n",
        "\n",
        "## Interactions Between Continuous Variables\n",
        "\n",
        "-   The final type of interaction is between two continuous variables\n",
        "\n",
        "-   Suppose we are interested in $$wage_{i} = \\beta_{0} + \\beta_{1}exper_{i} + \\beta_{2}educ_{i}+  \\beta_{3}(exper_{i} \\times educ_{i}) + u_{i}$$\n",
        "\n",
        "    -   $wage_{i}$ is an individual's wage in dollars\n",
        "\n",
        "    -   $exper_{i}$ is experience in years\n",
        "\n",
        "    -   $educ_{i}$ is total years of schooling\n",
        "\n",
        "-   This model allows effect of experience to depend on education\n",
        "\n",
        "    -   Also effect of education to depend on experience\n",
        "\n",
        "## Interactions Between Continuous Variables\n",
        "\n",
        "-   To see this, compute change in wage with experience $$\\frac{\\Delta E[wage_{i}|exper_{i},educ_{i}] }{\\Delta exper_{i}} =  \\beta_{1} + \\beta_{3}educ_{i}$$\n",
        "\n",
        "-   There are two components to the effect\n",
        "\n",
        "    -   $\\beta_{1}$: effect of experience on wages when education is zero\n",
        "\n",
        "    -   $\\beta_{3}$: change in the effect with each additional year of education\n",
        "\n",
        "-   The effect of education on wages is $$\\frac{\\Delta E[wage_{i}|exper_{i},educ_{i}] }{\\Delta educ_{i}} =  \\beta_{2} + \\beta_{3}exper_{i}$$\n",
        "\n",
        "    -   $\\beta_{2}$: effect of education on wages when experience is zero\n",
        "\n",
        "    -   $\\beta_{3}$: change in the effect with each additional year of experience\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   A model with interactions between experience and earnings is $$wage_{i} = \\beta_{0} + \\beta_{1}exper_{i} + \\beta_{2}educ_{i}+  \\beta_{3}(exper_{i} \\times educ_{i}) + u_{i}$$\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    .  gen yrxfte11_yrschl18 = yrxfte11*yrschl18;\n",
        "    .  regress cmphrw28 yrxfte11 yrschl18 yrxfte11_yrschl18, robust  ;\n",
        "\n",
        "    Linear regression                               Number of obs     =     15,817\n",
        "                                                    F(3, 15813)       =    1094.72\n",
        "                                                    Prob > F          =     0.0000\n",
        "                                                    R-squared         =     0.2265\n",
        "                                                    Root MSE          =     12.179\n",
        "\n",
        "    -----------------------------------------------------------------------------------\n",
        "                      |               Robust\n",
        "             cmphrw28 |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
        "    ------------------+----------------------------------------------------------------\n",
        "             yrxfte11 |  -.1525336   .0462564    -3.30   0.001    -.2432013   -.0618658\n",
        "             yrschl18 |   1.531803   .0675118    22.69   0.000     1.399472    1.664134\n",
        "    yrxfte11_yrschl18 |    .033486   .0036474     9.18   0.000     .0263366    .0406355\n",
        "                _cons |  -.5684791   .9001661    -0.63   0.528    -2.332907    1.195949\n",
        "    -----------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   Here are all the results from the regressions together\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "     estout dummy dummyinteract intershift interslopeshift slopeshift continteract, \n",
        "     cells(b(star fmt(3)) se(par fmt(3))) starlevels(* 0.05 ** 0.01 ) stats(r2 r2_a rmse N,fmt(3 3 3 0 ));\n",
        "\n",
        "    ------------------------------------------------------------------------------------------------------\n",
        "                        dummy   dummyinter~t     intershift   interslope~t     slopeshift   continteract  \n",
        "                         b/se           b/se           b/se           b/se           b/se           b/se  \n",
        "    ------------------------------------------------------------------------------------------------------\n",
        "    female             -4.246**       -1.912**       -5.311**       -5.433**                              \n",
        "                      (0.211)        (0.277)        (0.199)        (1.093)                                \n",
        "    married             5.093**        7.099**                                                            \n",
        "                      (0.208)        (0.313)                                                              \n",
        "    female_mar~d                      -4.143**                                                            \n",
        "                                     (0.412)                                                              \n",
        "    yrschl18                                          2.078**        2.075**        2.239**        1.532**\n",
        "                                                    (0.042)        (0.063)        (0.045)        (0.068)  \n",
        "    female_yr~18                                                     0.009         -0.368**               \n",
        "                                                                   (0.083)        (0.015)                 \n",
        "    yrxfte11                                                                                      -0.153**\n",
        "                                                                                                 (0.046)  \n",
        "    yrxfte11_~18                                                                                   0.033**\n",
        "                                                                                                 (0.004)  \n",
        "    _cons              25.747**       24.576**        0.317          0.370         -1.967**       -0.568  \n",
        "                      (0.180)        (0.206)        (0.552)        (0.814)        (0.562)        (0.900)  \n",
        "    ------------------------------------------------------------------------------------------------------\n",
        "    r2                  0.059          0.064          0.192          0.192          0.190          0.226  \n",
        "    r2_a                0.059          0.064          0.192          0.192          0.190          0.226  \n",
        "    rmse               13.432         13.393         12.448         12.449         12.459         12.179  \n",
        "    N                   15817          15817          15817          15817          15817          15817  \n",
        "    ------------------------------------------------------------------------------------------------------\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   **Model 1** allows for different intercepts for women and married people\n",
        "\n",
        "    -   Gender gap does not depend on marriage; marriage premium does not depend on gender\n",
        "\n",
        "    -   Women earn \\$4.25 less than men, married people earn \\$5.09 more than non-married people\n",
        "\n",
        "-   **Model 2** allows gender gap to depend on marriage; marriage gap to depend on gender\n",
        "\n",
        "    -   Gender gap for unmarried is -\\$1.91\n",
        "\n",
        "    -   Gender gap for married people is wider, equal to \\$-1.91 - \\$4.14\n",
        "\n",
        "-   **Model 3** estimates returns to schooling, allows intercept shift for women\n",
        "\n",
        "    -   Wages for women are \\$5.43 lower regardless of schooling\n",
        "\n",
        "    -   Return to schooling is \\$2.08 for women and men\n",
        "\n",
        "-   **Model 4** allows intercept and slope to differ for women\n",
        "\n",
        "    -   Wages for women are \\$5.31 lower regardless of schooling\n",
        "\n",
        "    -   Return to schooling is \\$2.08 for men, \\$2.09 for women\n",
        "\n",
        "## Example with Stata {background-color=\"#d9edc2\"}\n",
        "\n",
        "-   **Model 5** allows only slope to differ for women\n",
        "\n",
        "    -   Intercept is the same for men and women\n",
        "\n",
        "    -   Return to schooling is \\$2.24 for men, \\$1.87 for women\n",
        "\n",
        "-   **Model 6** allows interaction in effects of experience and education\n",
        "\n",
        "    -   Return to experience is increasing in education\n",
        "\n",
        "    -   Return to education is increasing in experience\n",
        "\n",
        "# Nonlinear Effects of Student Teacher Ratio on Test Scores\n",
        "\n",
        "## Introduction\n",
        "\n",
        "-   We end the chapter by revisiting the effect of class size and test scores\n",
        "\n",
        "-   Our models until now have been linear\n",
        "\n",
        "    -   One extra student has same effect on test scores regardless of class size\n",
        "\n",
        "-   This section generalizes that linear model in two ways\n",
        "\n",
        "-   Includes interaction terms with other variables\n",
        "\n",
        "    -   Lets class size effect depend on values of other variables\n",
        "\n",
        "    <!-- -->\n",
        "\n",
        "    -   Allows for nonlinearities in the class size effect\n",
        "\n",
        "        -   Lets class size effect depend on class size\n",
        "\n",
        "-   Example also uses hypothesis testing techniques learned earlier\n",
        "\n",
        "## Introduction\n",
        "\n",
        "![](table831.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Introduction\n",
        "\n",
        "![](table832.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Introduction\n",
        "\n",
        "![](table833.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Base Specification\n",
        "\n",
        "-   Column 1 contains the base specification\n",
        "\n",
        "-   Model is linear in student teacher ratio, with small set of controls\n",
        "\n",
        "    -   \\% ESL\n",
        "\n",
        "    -   \\% Free/Reduced Lunch\n",
        "\n",
        "-   Slope on class size is what we have seen before\n",
        "\n",
        "    -   One more student per teacher lowers test scores by one point\n",
        "\n",
        "    -   Significant at the 1% level\n",
        "\n",
        "## Alternative Specification with Income Control\n",
        "\n",
        "-   Column 2 adds log district income to the base specification\n",
        "\n",
        "-   Slope on class size falls compared to base\n",
        "\n",
        "    -   One more student per teacher lowers test scores by 0.73 points\n",
        "\n",
        "    -   Significant at the 1% level\n",
        "\n",
        "-   Important to be careful with interpretation of slope on income\n",
        "\n",
        "    -   Measured in logarithms\n",
        "\n",
        "    -   Effect of 1% increase in income on test scores is $\\frac{\\hat{\\beta}_{inc} }{100} = \\frac{11.57}{100} = 0.1157$\n",
        "\n",
        "    -   Statistically significant at 1% level\n",
        "\n",
        "    -   It is a relatively small coefficient\n",
        "\n",
        "## Interaction with High Fraction ESL\n",
        "\n",
        "-   Columns 3-4 explore interaction terms with $HiEL_{i}$\n",
        "\n",
        "    -   $HiEL_{i} = 1$ when fraction of English learners $>10\\%$\n",
        "\n",
        "-   Models include $HiEL_{i}$ on its own and interacted with $STR_{i}$\n",
        "\n",
        "    -   Allows intercept shift for districts with high % ESL\n",
        "\n",
        "    -   Also allows different slopes on $STR_{i}$ for high and low % ESL districts\n",
        "\n",
        "-   Using column 3, interpretation on $STR_{i}$ slope in first row changes\n",
        "\n",
        "    -   Adding one more student reduces scores by 0.97 *for districts with low fraction ESL*\n",
        "\n",
        "        -   This is slope on $STR_{i}$ for districts where $HiEL_{i} = 0$\n",
        "\n",
        "## Interaction with High Fraction ESL\n",
        "\n",
        "-   Coefficient on $HiEL_{i} \\times STR_{i}$ is *difference* in slope for high ESL districts\n",
        "\n",
        "    -   Slope on $STR_{i}$ is -1.28 lower for $HiEL_{i} = 1$\n",
        "\n",
        "    -   Total slope on $STR_{i}$ when $HiEL_{i} = 1$ is $-0.97 - 1.28 = -2.25$\n",
        "\n",
        "    -   Effect of additional student is stronger when high % ESL\n",
        "\n",
        "    -   But, coefficient on interaction is statistically insignificant\n",
        "\n",
        "-   Coefficient on $HiEL_{i}$ measures intercept shift\n",
        "\n",
        "    -   Difference in predicted test scores when other variables are zero\n",
        "\n",
        "    -   $HiEL_{i} = 1$ has higher intercept by about 5.64 points\n",
        "\n",
        "-   Column 4 is same idea, but adds free lunch and income\n",
        "\n",
        "    -   Slope on $STR_{i}$ when $HiEL_{i} = 0$ is -0.53\n",
        "\n",
        "    -   Slope on $STR_{i}$ when $HiEL_{i} = 1$ is $-0.53 - 0.58 = -1.11$\n",
        "\n",
        "    -   Upward intercept shift when $HiEL_{i} = 1$ is about the same\n",
        "\n",
        "## Nonlinearities in Test Score Effect\n",
        "\n",
        "-   Columns 5-7 explore nonlinearities in the class size effect\n",
        "\n",
        "    -   With polynomial functions\n",
        "\n",
        "-   Column 5 adds a cubic polynomial in $STR_{i}$\n",
        "\n",
        "    -   Coefficients on all polynomial terms are statistically significant\n",
        "\n",
        "        -   So we would want to keep nonlinear terms in the regression\n",
        "\n",
        "    -   Interpretation is tricky\n",
        "\n",
        "        -   With a cubic, effect of $STR_{i}$ on test scores is $\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta STR_{i}} = \\beta_{str} + 2\\beta_{str^2}STR_{i} + 3\\beta_{str^3}STR_{i}^2$\n",
        "\n",
        "        -   Need to know $STR_{i}$ to compute this effect\n",
        "\n",
        "        -   With 20 students, slope is $\\frac{\\Delta \\hat{TestScore}_{i}}{\\Delta STR_{i}} = 64.33 + 2(-3.42)(20) + 3(0.059)(20)^2 = -1.67$\n",
        "\n",
        "    -   Also note intecept shift downward for high ESL districts\n",
        "\n",
        "## Nonlinearities in Test Score Effect\n",
        "\n",
        "-   Column 7 reports very similar specification\n",
        "\n",
        "    -   Difference is $HiEL$ dummy replaced with %ESL\n",
        "\n",
        "    -   Estimates on polynomial terms are very similar\n",
        "\n",
        "-   Column 6 interacts nonlinear function in $STR_{i}$ with $HiEL$\n",
        "\n",
        "    -   Allows nonlinear function in $STR_{i}$ to differ between high and low ESL districts\n",
        "\n",
        "    -   Interaction terms are *difference* in polynomial terms when $HiEL_{i} = 1$\n",
        "\n",
        "        -   These are significant at 5% level, suggesting different relationship in high vs low ESL districts\n",
        "\n",
        "        -   Also, reject null that interaction terms are jointly zero at 5% level\n",
        "\n",
        "## Nonlinearities in Test Score Effect\n",
        "\n",
        "![](nonlineartestscore.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Nonlinearities in Test Score Effect\n",
        "\n",
        "![](interacttestscore.jpg){fig-align=\"center\" width=\"7in\"}\n",
        "\n",
        "## Summary\n",
        "\n",
        "-   Table 8.3 in text presents many specifications\n",
        "\n",
        "-   Here are the main takeaways\n",
        "\n",
        "    -   Omitted variables bias is an issue\n",
        "\n",
        "        -   Controlling for economic background is important\n",
        "\n",
        "    -   There are nonlinearities in the effect of class size on test scores\n",
        "\n",
        "        -   All of the polynomial terms in regressions are statistically significant\n",
        "\n",
        "        -   Means effect of class size depends on size of class\n",
        "\n",
        "    -   Relationship between class size and test scores is different in districts with high %ESL\n",
        "\n",
        "        -   In columns 3 and 4, accept null that difference in slope is zero\n",
        "\n",
        "        -   However, in column 6, differences in slope are significant when we allow nonlinearities"
      ],
      "id": "d92319c3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}